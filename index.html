<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=cGvuclDC_Z1vE_cnVEU6Ae_NZQ7StBcqH_vXVqoPMX0);.lst-kix_9mugulzewaai-1>li:before{content:"\0025cb   "}.lst-kix_9mugulzewaai-0>li:before{content:"\0025cf   "}.lst-kix_2jj8uwmiysve-3>li:before{content:"\0025cf   "}.lst-kix_2jj8uwmiysve-4>li:before{content:"\0025cb   "}.lst-kix_9mugulzewaai-6>li:before{content:"\0025cf   "}.lst-kix_2jj8uwmiysve-6>li:before{content:"\0025cf   "}.lst-kix_2jj8uwmiysve-5>li:before{content:"\0025a0   "}.lst-kix_2jj8uwmiysve-7>li:before{content:"\0025cb   "}.lst-kix_9mugulzewaai-5>li:before{content:"\0025a0   "}.lst-kix_9mugulzewaai-4>li:before{content:"\0025cb   "}.lst-kix_9mugulzewaai-3>li:before{content:"\0025cf   "}.lst-kix_2jj8uwmiysve-8>li:before{content:"\0025a0   "}.lst-kix_9mugulzewaai-2>li:before{content:"\0025a0   "}.lst-kix_nyqoq4wyl84v-8>li:before{content:"\0025a0   "}.lst-kix_se3dboe4l03a-7>li:before{content:"\0025cb   "}.lst-kix_nyqoq4wyl84v-3>li:before{content:"\0025cf   "}.lst-kix_se3dboe4l03a-8>li:before{content:"\0025a0   "}.lst-kix_9mugulzewaai-7>li:before{content:"\0025cb   "}.lst-kix_nyqoq4wyl84v-4>li:before{content:"\0025cb   "}.lst-kix_9mugulzewaai-8>li:before{content:"\0025a0   "}.lst-kix_nyqoq4wyl84v-5>li:before{content:"\0025a0   "}.lst-kix_nyqoq4wyl84v-6>li:before{content:"\0025cf   "}.lst-kix_nyqoq4wyl84v-7>li:before{content:"\0025cb   "}ul.lst-kix_sq3cvxxcbcth-6{list-style-type:none}.lst-kix_cwpm0c9kexa-8>li:before{content:"\0025a0   "}ul.lst-kix_sq3cvxxcbcth-5{list-style-type:none}ul.lst-kix_sq3cvxxcbcth-8{list-style-type:none}ul.lst-kix_sq3cvxxcbcth-7{list-style-type:none}ul.lst-kix_sq3cvxxcbcth-2{list-style-type:none}ul.lst-kix_sq3cvxxcbcth-1{list-style-type:none}ul.lst-kix_sq3cvxxcbcth-4{list-style-type:none}ul.lst-kix_fweaixhedeav-1{list-style-type:none}ul.lst-kix_sq3cvxxcbcth-3{list-style-type:none}ul.lst-kix_fweaixhedeav-0{list-style-type:none}.lst-kix_cwpm0c9kexa-5>li:before{content:"\0025a0   "}.lst-kix_49l6hhcwk3z6-0>li:before{content:"\0025cf   "}.lst-kix_cwpm0c9kexa-6>li:before{content:"\0025cf   "}.lst-kix_se3dboe4l03a-0>li:before{content:"\0025cf   "}.lst-kix_se3dboe4l03a-1>li:before{content:"\0025cb   "}.lst-kix_cwpm0c9kexa-7>li:before{content:"\0025cb   "}.lst-kix_se3dboe4l03a-2>li:before{content:"\0025a0   "}.lst-kix_se3dboe4l03a-3>li:before{content:"\0025cf   "}ul.lst-kix_fweaixhedeav-3{list-style-type:none}.lst-kix_se3dboe4l03a-6>li:before{content:"\0025cf   "}ul.lst-kix_fweaixhedeav-2{list-style-type:none}ul.lst-kix_sq3cvxxcbcth-0{list-style-type:none}ul.lst-kix_fweaixhedeav-5{list-style-type:none}ul.lst-kix_fweaixhedeav-4{list-style-type:none}ul.lst-kix_fweaixhedeav-7{list-style-type:none}.lst-kix_se3dboe4l03a-4>li:before{content:"\0025cb   "}.lst-kix_se3dboe4l03a-5>li:before{content:"\0025a0   "}ul.lst-kix_fweaixhedeav-6{list-style-type:none}ul.lst-kix_fweaixhedeav-8{list-style-type:none}.lst-kix_49l6hhcwk3z6-8>li:before{content:"\0025a0   "}ul.lst-kix_2jj8uwmiysve-8{list-style-type:none}.lst-kix_49l6hhcwk3z6-7>li:before{content:"\0025cb   "}ul.lst-kix_2jj8uwmiysve-4{list-style-type:none}ul.lst-kix_2jj8uwmiysve-5{list-style-type:none}ul.lst-kix_2jj8uwmiysve-6{list-style-type:none}ul.lst-kix_2jj8uwmiysve-7{list-style-type:none}.lst-kix_49l6hhcwk3z6-6>li:before{content:"\0025cf   "}ul.lst-kix_2jj8uwmiysve-0{list-style-type:none}ul.lst-kix_bdvlsg70sq8v-6{list-style-type:none}ul.lst-kix_2jj8uwmiysve-1{list-style-type:none}ul.lst-kix_bdvlsg70sq8v-7{list-style-type:none}ul.lst-kix_2jj8uwmiysve-2{list-style-type:none}ul.lst-kix_bdvlsg70sq8v-4{list-style-type:none}ul.lst-kix_2jj8uwmiysve-3{list-style-type:none}ul.lst-kix_bdvlsg70sq8v-5{list-style-type:none}.lst-kix_49l6hhcwk3z6-3>li:before{content:"\0025cf   "}.lst-kix_49l6hhcwk3z6-5>li:before{content:"\0025a0   "}ul.lst-kix_bdvlsg70sq8v-2{list-style-type:none}ul.lst-kix_bdvlsg70sq8v-3{list-style-type:none}ul.lst-kix_bdvlsg70sq8v-0{list-style-type:none}ul.lst-kix_bdvlsg70sq8v-1{list-style-type:none}.lst-kix_49l6hhcwk3z6-4>li:before{content:"\0025cb   "}.lst-kix_2jj8uwmiysve-2>li:before{content:"\0025a0   "}.lst-kix_49l6hhcwk3z6-1>li:before{content:"\0025cb   "}.lst-kix_2jj8uwmiysve-0>li:before{content:"\0025cf   "}.lst-kix_2jj8uwmiysve-1>li:before{content:"\0025cb   "}ul.lst-kix_bdvlsg70sq8v-8{list-style-type:none}.lst-kix_49l6hhcwk3z6-2>li:before{content:"\0025a0   "}.lst-kix_41gu93x5rvez-0>li:before{content:"\0025cf   "}.lst-kix_e7bd6ixhmenr-1>li:before{content:"\0025cb   "}.lst-kix_e7bd6ixhmenr-5>li:before{content:"\0025a0   "}.lst-kix_sq3cvxxcbcth-0>li:before{content:"\0025cf   "}.lst-kix_e7bd6ixhmenr-3>li:before{content:"\0025cf   "}.lst-kix_i6ow0hftaxwl-8>li:before{content:"\0025a0   "}.lst-kix_sq3cvxxcbcth-2>li:before{content:"\0025a0   "}.lst-kix_sq3cvxxcbcth-4>li:before{content:"\0025cb   "}.lst-kix_41gu93x5rvez-4>li:before{content:"\0025cb   "}.lst-kix_ohdwmula8yum-3>li:before{content:"\0025cf   "}.lst-kix_ohdwmula8yum-7>li:before{content:"\0025cb   "}.lst-kix_i6ow0hftaxwl-6>li:before{content:"\0025cf   "}.lst-kix_41gu93x5rvez-2>li:before{content:"\0025a0   "}.lst-kix_sq3cvxxcbcth-6>li:before{content:"\0025cf   "}.lst-kix_ohdwmula8yum-5>li:before{content:"\0025a0   "}.lst-kix_e7bd6ixhmenr-7>li:before{content:"\0025cb   "}.lst-kix_i6ow0hftaxwl-4>li:before{content:"\0025cb   "}.lst-kix_sq3cvxxcbcth-8>li:before{content:"\0025a0   "}ul.lst-kix_9mugulzewaai-1{list-style-type:none}ul.lst-kix_nzvk1p4cks1-4{list-style-type:none}ul.lst-kix_9mugulzewaai-2{list-style-type:none}ul.lst-kix_nzvk1p4cks1-3{list-style-type:none}ul.lst-kix_nzvk1p4cks1-6{list-style-type:none}ul.lst-kix_9mugulzewaai-0{list-style-type:none}.lst-kix_cwpm0c9kexa-0>li:before{content:"\0025cf   "}.lst-kix_cwpm0c9kexa-2>li:before{content:"\0025a0   "}ul.lst-kix_nzvk1p4cks1-5{list-style-type:none}ul.lst-kix_9mugulzewaai-5{list-style-type:none}ul.lst-kix_nzvk1p4cks1-0{list-style-type:none}ul.lst-kix_9mugulzewaai-6{list-style-type:none}ul.lst-kix_9mugulzewaai-3{list-style-type:none}ul.lst-kix_nzvk1p4cks1-2{list-style-type:none}ul.lst-kix_9mugulzewaai-4{list-style-type:none}ul.lst-kix_nzvk1p4cks1-1{list-style-type:none}.lst-kix_cwpm0c9kexa-4>li:before{content:"\0025cb   "}ul.lst-kix_nzvk1p4cks1-8{list-style-type:none}ul.lst-kix_nzvk1p4cks1-7{list-style-type:none}ul.lst-kix_8isiubb4hy4m-2{list-style-type:none}ul.lst-kix_8isiubb4hy4m-1{list-style-type:none}ul.lst-kix_8isiubb4hy4m-4{list-style-type:none}ul.lst-kix_8isiubb4hy4m-3{list-style-type:none}ul.lst-kix_8isiubb4hy4m-6{list-style-type:none}ul.lst-kix_8isiubb4hy4m-5{list-style-type:none}ul.lst-kix_8isiubb4hy4m-8{list-style-type:none}ul.lst-kix_8isiubb4hy4m-7{list-style-type:none}ul.lst-kix_9mugulzewaai-7{list-style-type:none}ul.lst-kix_9mugulzewaai-8{list-style-type:none}.lst-kix_nyqoq4wyl84v-2>li:before{content:"\0025a0   "}ul.lst-kix_mq787rs9iun6-7{list-style-type:none}ul.lst-kix_mq787rs9iun6-8{list-style-type:none}.lst-kix_nyqoq4wyl84v-0>li:before{content:"\0025cf   "}ul.lst-kix_8isiubb4hy4m-0{list-style-type:none}.lst-kix_q1k1i97sl5wh-6>li:before{content:"\0025cf   "}.lst-kix_q1k1i97sl5wh-8>li:before{content:"\0025a0   "}ul.lst-kix_mq787rs9iun6-1{list-style-type:none}ul.lst-kix_mq787rs9iun6-2{list-style-type:none}ul.lst-kix_mq787rs9iun6-0{list-style-type:none}ul.lst-kix_mq787rs9iun6-5{list-style-type:none}ul.lst-kix_mq787rs9iun6-6{list-style-type:none}ul.lst-kix_mq787rs9iun6-3{list-style-type:none}.lst-kix_ohdwmula8yum-1>li:before{content:"\0025cb   "}ul.lst-kix_mq787rs9iun6-4{list-style-type:none}.lst-kix_41gu93x5rvez-6>li:before{content:"\0025cf   "}.lst-kix_41gu93x5rvez-8>li:before{content:"\0025a0   "}.lst-kix_r2c05k5a1kzz-8>li:before{content:"\0025a0   "}.lst-kix_hjsi3qaxptbv-0>li:before{content:"\0025cf   "}.lst-kix_hjsi3qaxptbv-1>li:before{content:"\0025cb   "}.lst-kix_hjsi3qaxptbv-4>li:before{content:"\0025cb   "}.lst-kix_hjsi3qaxptbv-5>li:before{content:"\0025a0   "}.lst-kix_r2c05k5a1kzz-4>li:before{content:"\0025cb   "}.lst-kix_r2c05k5a1kzz-3>li:before{content:"\0025cf   "}.lst-kix_r2c05k5a1kzz-0>li:before{content:"\0025cf   "}.lst-kix_mq787rs9iun6-4>li:before{content:"\0025cb   "}.lst-kix_mq787rs9iun6-3>li:before{content:"\0025cf   "}.lst-kix_pnndopbxg7rj-0>li:before{content:"\0025cf   "}.lst-kix_mq787rs9iun6-0>li:before{content:"\0025cf   "}.lst-kix_q1k1i97sl5wh-5>li:before{content:"\0025a0   "}.lst-kix_pnndopbxg7rj-1>li:before{content:"\0025cb   "}.lst-kix_pnndopbxg7rj-4>li:before{content:"\0025cb   "}.lst-kix_pnndopbxg7rj-8>li:before{content:"\0025a0   "}.lst-kix_ri3rwq8w4csm-2>li:before{content:"\0025a0   "}.lst-kix_q1k1i97sl5wh-1>li:before{content:"\0025cb   "}.lst-kix_q1k1i97sl5wh-2>li:before{content:"\0025a0   "}.lst-kix_pnndopbxg7rj-5>li:before{content:"\0025a0   "}.lst-kix_ri3rwq8w4csm-7>li:before{content:"\0025cb   "}.lst-kix_ri3rwq8w4csm-6>li:before{content:"\0025cf   "}.lst-kix_ri3rwq8w4csm-3>li:before{content:"\0025cf   "}.lst-kix_r2c05k5a1kzz-7>li:before{content:"\0025cb   "}.lst-kix_nzvk1p4cks1-1>li:before{content:"\0025cb   "}.lst-kix_nzvk1p4cks1-2>li:before{content:"\0025a0   "}.lst-kix_sbvy1wy9e6k8-3>li:before{content:"\0025cf   "}.lst-kix_sbvy1wy9e6k8-4>li:before{content:"\0025cb   "}.lst-kix_i6ow0hftaxwl-1>li:before{content:"\0025cb   "}.lst-kix_i6ow0hftaxwl-2>li:before{content:"\0025a0   "}.lst-kix_nzvk1p4cks1-5>li:before{content:"\0025a0   "}.lst-kix_nzvk1p4cks1-6>li:before{content:"\0025cf   "}.lst-kix_mq787rs9iun6-7>li:before{content:"\0025cb   "}.lst-kix_hjsi3qaxptbv-8>li:before{content:"\0025a0   "}.lst-kix_sbvy1wy9e6k8-7>li:before{content:"\0025cb   "}.lst-kix_sbvy1wy9e6k8-8>li:before{content:"\0025a0   "}.lst-kix_mq787rs9iun6-8>li:before{content:"\0025a0   "}.lst-kix_e7bd6ixhmenr-4>li:before{content:"\0025cb   "}.lst-kix_41gu93x5rvez-5>li:before{content:"\0025a0   "}.lst-kix_sq3cvxxcbcth-3>li:before{content:"\0025cf   "}.lst-kix_ohdwmula8yum-2>li:before{content:"\0025a0   "}.lst-kix_ohdwmula8yum-6>li:before{content:"\0025cf   "}.lst-kix_sq3cvxxcbcth-7>li:before{content:"\0025cb   "}.lst-kix_sbvy1wy9e6k8-0>li:before{content:"\0025cf   "}.lst-kix_i6ow0hftaxwl-5>li:before{content:"\0025a0   "}.lst-kix_e7bd6ixhmenr-8>li:before{content:"\0025a0   "}.lst-kix_41gu93x5rvez-1>li:before{content:"\0025cb   "}ul.lst-kix_se3dboe4l03a-8{list-style-type:none}.lst-kix_3urcczrnk5zr-0>li:before{content:"\0025cf   "}ul.lst-kix_se3dboe4l03a-1{list-style-type:none}ul.lst-kix_se3dboe4l03a-0{list-style-type:none}ul.lst-kix_se3dboe4l03a-3{list-style-type:none}ul.lst-kix_se3dboe4l03a-2{list-style-type:none}ul.lst-kix_se3dboe4l03a-5{list-style-type:none}.lst-kix_8isiubb4hy4m-6>li:before{content:"\0025cf   "}ul.lst-kix_se3dboe4l03a-4{list-style-type:none}ul.lst-kix_se3dboe4l03a-7{list-style-type:none}ul.lst-kix_se3dboe4l03a-6{list-style-type:none}ul.lst-kix_e7bd6ixhmenr-4{list-style-type:none}ul.lst-kix_e7bd6ixhmenr-5{list-style-type:none}ul.lst-kix_e7bd6ixhmenr-2{list-style-type:none}ul.lst-kix_e7bd6ixhmenr-3{list-style-type:none}ul.lst-kix_e7bd6ixhmenr-0{list-style-type:none}ul.lst-kix_e7bd6ixhmenr-1{list-style-type:none}.lst-kix_cwpm0c9kexa-1>li:before{content:"\0025cb   "}.lst-kix_e7bd6ixhmenr-0>li:before{content:"\0025cf   "}ul.lst-kix_e7bd6ixhmenr-8{list-style-type:none}ul.lst-kix_e7bd6ixhmenr-6{list-style-type:none}ul.lst-kix_e7bd6ixhmenr-7{list-style-type:none}ul.lst-kix_q1k1i97sl5wh-5{list-style-type:none}ul.lst-kix_q1k1i97sl5wh-6{list-style-type:none}ul.lst-kix_q1k1i97sl5wh-7{list-style-type:none}ul.lst-kix_q1k1i97sl5wh-8{list-style-type:none}.lst-kix_v71v1sb3yh2k-3>li:before{content:"\0025cf   "}.lst-kix_nyqoq4wyl84v-1>li:before{content:"\0025cb   "}ul.lst-kix_q1k1i97sl5wh-0{list-style-type:none}ul.lst-kix_q1k1i97sl5wh-1{list-style-type:none}.lst-kix_3urcczrnk5zr-4>li:before{content:"\0025cb   "}ul.lst-kix_q1k1i97sl5wh-2{list-style-type:none}ul.lst-kix_q1k1i97sl5wh-3{list-style-type:none}ul.lst-kix_q1k1i97sl5wh-4{list-style-type:none}.lst-kix_fweaixhedeav-1>li:before{content:"\0025cb   "}.lst-kix_fweaixhedeav-5>li:before{content:"\0025a0   "}ul.lst-kix_v71v1sb3yh2k-6{list-style-type:none}ul.lst-kix_v71v1sb3yh2k-7{list-style-type:none}ul.lst-kix_v71v1sb3yh2k-4{list-style-type:none}ul.lst-kix_v71v1sb3yh2k-5{list-style-type:none}ul.lst-kix_v71v1sb3yh2k-2{list-style-type:none}.lst-kix_3urcczrnk5zr-8>li:before{content:"\0025a0   "}ul.lst-kix_v71v1sb3yh2k-3{list-style-type:none}ul.lst-kix_v71v1sb3yh2k-0{list-style-type:none}ul.lst-kix_v71v1sb3yh2k-1{list-style-type:none}.lst-kix_v71v1sb3yh2k-7>li:before{content:"\0025cb   "}ul.lst-kix_v71v1sb3yh2k-8{list-style-type:none}ul.lst-kix_49l6hhcwk3z6-1{list-style-type:none}ul.lst-kix_49l6hhcwk3z6-0{list-style-type:none}ul.lst-kix_nyqoq4wyl84v-4{list-style-type:none}ul.lst-kix_49l6hhcwk3z6-5{list-style-type:none}ul.lst-kix_nyqoq4wyl84v-3{list-style-type:none}ul.lst-kix_49l6hhcwk3z6-4{list-style-type:none}ul.lst-kix_nyqoq4wyl84v-2{list-style-type:none}ul.lst-kix_49l6hhcwk3z6-3{list-style-type:none}ul.lst-kix_nyqoq4wyl84v-1{list-style-type:none}ul.lst-kix_49l6hhcwk3z6-2{list-style-type:none}ul.lst-kix_nyqoq4wyl84v-0{list-style-type:none}ul.lst-kix_49l6hhcwk3z6-8{list-style-type:none}ul.lst-kix_49l6hhcwk3z6-7{list-style-type:none}ul.lst-kix_49l6hhcwk3z6-6{list-style-type:none}.lst-kix_bdvlsg70sq8v-5>li:before{content:"\0025a0   "}.lst-kix_bdvlsg70sq8v-7>li:before{content:"\0025cb   "}ul.lst-kix_ri3rwq8w4csm-0{list-style-type:none}.lst-kix_bdvlsg70sq8v-4>li:before{content:"\0025cb   "}.lst-kix_bdvlsg70sq8v-8>li:before{content:"\0025a0   "}ul.lst-kix_ri3rwq8w4csm-3{list-style-type:none}ul.lst-kix_ri3rwq8w4csm-4{list-style-type:none}ul.lst-kix_ri3rwq8w4csm-1{list-style-type:none}ul.lst-kix_ri3rwq8w4csm-2{list-style-type:none}ul.lst-kix_ri3rwq8w4csm-7{list-style-type:none}ul.lst-kix_ri3rwq8w4csm-8{list-style-type:none}ul.lst-kix_ri3rwq8w4csm-5{list-style-type:none}.lst-kix_bdvlsg70sq8v-6>li:before{content:"\0025cf   "}ul.lst-kix_ri3rwq8w4csm-6{list-style-type:none}.lst-kix_bdvlsg70sq8v-0>li:before{content:"\0025cf   "}.lst-kix_bdvlsg70sq8v-1>li:before{content:"\0025cb   "}.lst-kix_bdvlsg70sq8v-3>li:before{content:"\0025cf   "}.lst-kix_bdvlsg70sq8v-2>li:before{content:"\0025a0   "}ul.lst-kix_nyqoq4wyl84v-8{list-style-type:none}ul.lst-kix_nyqoq4wyl84v-7{list-style-type:none}ul.lst-kix_nyqoq4wyl84v-6{list-style-type:none}ul.lst-kix_nyqoq4wyl84v-5{list-style-type:none}.lst-kix_8isiubb4hy4m-0>li:before{content:"\0025cf   "}.lst-kix_8isiubb4hy4m-1>li:before{content:"\0025cb   "}.lst-kix_8isiubb4hy4m-2>li:before{content:"\0025a0   "}ul.lst-kix_3urcczrnk5zr-8{list-style-type:none}ul.lst-kix_3urcczrnk5zr-7{list-style-type:none}ul.lst-kix_3urcczrnk5zr-6{list-style-type:none}ul.lst-kix_3urcczrnk5zr-5{list-style-type:none}ul.lst-kix_3urcczrnk5zr-4{list-style-type:none}ul.lst-kix_3urcczrnk5zr-3{list-style-type:none}ul.lst-kix_3urcczrnk5zr-2{list-style-type:none}ul.lst-kix_3urcczrnk5zr-1{list-style-type:none}ul.lst-kix_3urcczrnk5zr-0{list-style-type:none}ul.lst-kix_hjsi3qaxptbv-5{list-style-type:none}ul.lst-kix_hjsi3qaxptbv-4{list-style-type:none}ul.lst-kix_hjsi3qaxptbv-7{list-style-type:none}ul.lst-kix_hjsi3qaxptbv-6{list-style-type:none}ul.lst-kix_hjsi3qaxptbv-8{list-style-type:none}ul.lst-kix_hjsi3qaxptbv-1{list-style-type:none}ul.lst-kix_hjsi3qaxptbv-0{list-style-type:none}ul.lst-kix_hjsi3qaxptbv-3{list-style-type:none}ul.lst-kix_hjsi3qaxptbv-2{list-style-type:none}.lst-kix_8isiubb4hy4m-3>li:before{content:"\0025cf   "}.lst-kix_fweaixhedeav-0>li:before{content:"\0025cf   "}.lst-kix_8isiubb4hy4m-7>li:before{content:"\0025cb   "}.lst-kix_8isiubb4hy4m-5>li:before{content:"\0025a0   "}.lst-kix_v71v1sb3yh2k-0>li:before{content:"\0025cf   "}.lst-kix_v71v1sb3yh2k-2>li:before{content:"\0025a0   "}.lst-kix_v71v1sb3yh2k-4>li:before{content:"\0025cb   "}.lst-kix_3urcczrnk5zr-7>li:before{content:"\0025cb   "}.lst-kix_3urcczrnk5zr-5>li:before{content:"\0025a0   "}.lst-kix_3urcczrnk5zr-1>li:before{content:"\0025cb   "}.lst-kix_3urcczrnk5zr-3>li:before{content:"\0025cf   "}.lst-kix_fweaixhedeav-2>li:before{content:"\0025a0   "}.lst-kix_fweaixhedeav-4>li:before{content:"\0025cb   "}.lst-kix_fweaixhedeav-8>li:before{content:"\0025a0   "}.lst-kix_v71v1sb3yh2k-8>li:before{content:"\0025a0   "}.lst-kix_fweaixhedeav-6>li:before{content:"\0025cf   "}.lst-kix_v71v1sb3yh2k-6>li:before{content:"\0025cf   "}.lst-kix_hjsi3qaxptbv-2>li:before{content:"\0025a0   "}.lst-kix_hjsi3qaxptbv-3>li:before{content:"\0025cf   "}.lst-kix_r2c05k5a1kzz-6>li:before{content:"\0025cf   "}ul.lst-kix_ohdwmula8yum-8{list-style-type:none}.lst-kix_r2c05k5a1kzz-5>li:before{content:"\0025a0   "}ul.lst-kix_ohdwmula8yum-7{list-style-type:none}ul.lst-kix_ohdwmula8yum-6{list-style-type:none}ul.lst-kix_ohdwmula8yum-5{list-style-type:none}ul.lst-kix_ohdwmula8yum-4{list-style-type:none}ul.lst-kix_ohdwmula8yum-3{list-style-type:none}ul.lst-kix_ohdwmula8yum-2{list-style-type:none}ul.lst-kix_ohdwmula8yum-1{list-style-type:none}ul.lst-kix_ohdwmula8yum-0{list-style-type:none}ul.lst-kix_41gu93x5rvez-1{list-style-type:none}.lst-kix_mq787rs9iun6-5>li:before{content:"\0025a0   "}.lst-kix_ri3rwq8w4csm-8>li:before{content:"\0025a0   "}ul.lst-kix_41gu93x5rvez-0{list-style-type:none}ul.lst-kix_41gu93x5rvez-5{list-style-type:none}.lst-kix_r2c05k5a1kzz-2>li:before{content:"\0025a0   "}ul.lst-kix_41gu93x5rvez-4{list-style-type:none}ul.lst-kix_41gu93x5rvez-3{list-style-type:none}.lst-kix_r2c05k5a1kzz-1>li:before{content:"\0025cb   "}ul.lst-kix_41gu93x5rvez-2{list-style-type:none}.lst-kix_pnndopbxg7rj-2>li:before{content:"\0025a0   "}.lst-kix_mq787rs9iun6-1>li:before{content:"\0025cb   "}.lst-kix_mq787rs9iun6-2>li:before{content:"\0025a0   "}.lst-kix_q1k1i97sl5wh-4>li:before{content:"\0025cb   "}.lst-kix_pnndopbxg7rj-6>li:before{content:"\0025cf   "}.lst-kix_ri3rwq8w4csm-0>li:before{content:"\0025cf   "}.lst-kix_ri3rwq8w4csm-1>li:before{content:"\0025cb   "}.lst-kix_pnndopbxg7rj-3>li:before{content:"\0025cf   "}.lst-kix_pnndopbxg7rj-7>li:before{content:"\0025cb   "}ul.lst-kix_41gu93x5rvez-8{list-style-type:none}.lst-kix_q1k1i97sl5wh-3>li:before{content:"\0025cf   "}ul.lst-kix_41gu93x5rvez-7{list-style-type:none}ul.lst-kix_41gu93x5rvez-6{list-style-type:none}.lst-kix_q1k1i97sl5wh-0>li:before{content:"\0025cf   "}.lst-kix_ri3rwq8w4csm-4>li:before{content:"\0025cb   "}.lst-kix_ri3rwq8w4csm-5>li:before{content:"\0025a0   "}ul.lst-kix_cwpm0c9kexa-7{list-style-type:none}ul.lst-kix_cwpm0c9kexa-8{list-style-type:none}ul.lst-kix_cwpm0c9kexa-5{list-style-type:none}ul.lst-kix_cwpm0c9kexa-6{list-style-type:none}ul.lst-kix_cwpm0c9kexa-3{list-style-type:none}ul.lst-kix_cwpm0c9kexa-4{list-style-type:none}ul.lst-kix_cwpm0c9kexa-1{list-style-type:none}ul.lst-kix_cwpm0c9kexa-2{list-style-type:none}.lst-kix_nzvk1p4cks1-0>li:before{content:"\0025cf   "}.lst-kix_nzvk1p4cks1-4>li:before{content:"\0025cb   "}.lst-kix_nzvk1p4cks1-3>li:before{content:"\0025cf   "}ul.lst-kix_i6ow0hftaxwl-1{list-style-type:none}ul.lst-kix_i6ow0hftaxwl-0{list-style-type:none}.lst-kix_nzvk1p4cks1-7>li:before{content:"\0025cb   "}.lst-kix_sbvy1wy9e6k8-1>li:before{content:"\0025cb   "}.lst-kix_sbvy1wy9e6k8-5>li:before{content:"\0025a0   "}.lst-kix_nzvk1p4cks1-8>li:before{content:"\0025a0   "}ul.lst-kix_i6ow0hftaxwl-8{list-style-type:none}ul.lst-kix_i6ow0hftaxwl-7{list-style-type:none}ul.lst-kix_i6ow0hftaxwl-6{list-style-type:none}ul.lst-kix_i6ow0hftaxwl-5{list-style-type:none}ul.lst-kix_i6ow0hftaxwl-4{list-style-type:none}.lst-kix_sbvy1wy9e6k8-2>li:before{content:"\0025a0   "}ul.lst-kix_i6ow0hftaxwl-3{list-style-type:none}.lst-kix_i6ow0hftaxwl-0>li:before{content:"\0025cf   "}ul.lst-kix_i6ow0hftaxwl-2{list-style-type:none}.lst-kix_mq787rs9iun6-6>li:before{content:"\0025cf   "}.lst-kix_hjsi3qaxptbv-6>li:before{content:"\0025cf   "}.lst-kix_hjsi3qaxptbv-7>li:before{content:"\0025cb   "}.lst-kix_sbvy1wy9e6k8-6>li:before{content:"\0025cf   "}ul.lst-kix_sbvy1wy9e6k8-3{list-style-type:none}.lst-kix_e7bd6ixhmenr-2>li:before{content:"\0025a0   "}ul.lst-kix_sbvy1wy9e6k8-4{list-style-type:none}ul.lst-kix_sbvy1wy9e6k8-5{list-style-type:none}ul.lst-kix_sbvy1wy9e6k8-6{list-style-type:none}ul.lst-kix_sbvy1wy9e6k8-7{list-style-type:none}ul.lst-kix_sbvy1wy9e6k8-8{list-style-type:none}.lst-kix_ohdwmula8yum-8>li:before{content:"\0025a0   "}.lst-kix_sq3cvxxcbcth-1>li:before{content:"\0025cb   "}ul.lst-kix_sbvy1wy9e6k8-0{list-style-type:none}ul.lst-kix_sbvy1wy9e6k8-1{list-style-type:none}ul.lst-kix_sbvy1wy9e6k8-2{list-style-type:none}.lst-kix_ohdwmula8yum-4>li:before{content:"\0025cb   "}.lst-kix_i6ow0hftaxwl-7>li:before{content:"\0025cb   "}.lst-kix_41gu93x5rvez-3>li:before{content:"\0025cf   "}.lst-kix_e7bd6ixhmenr-6>li:before{content:"\0025cf   "}.lst-kix_i6ow0hftaxwl-3>li:before{content:"\0025cf   "}.lst-kix_sq3cvxxcbcth-5>li:before{content:"\0025a0   "}.lst-kix_8isiubb4hy4m-4>li:before{content:"\0025cb   "}ul.lst-kix_cwpm0c9kexa-0{list-style-type:none}.lst-kix_8isiubb4hy4m-8>li:before{content:"\0025a0   "}.lst-kix_cwpm0c9kexa-3>li:before{content:"\0025cf   "}.lst-kix_v71v1sb3yh2k-1>li:before{content:"\0025cb   "}ul.lst-kix_r2c05k5a1kzz-8{list-style-type:none}.lst-kix_v71v1sb3yh2k-5>li:before{content:"\0025a0   "}ul.lst-kix_pnndopbxg7rj-5{list-style-type:none}ul.lst-kix_pnndopbxg7rj-4{list-style-type:none}.lst-kix_3urcczrnk5zr-6>li:before{content:"\0025cf   "}ul.lst-kix_pnndopbxg7rj-3{list-style-type:none}ul.lst-kix_pnndopbxg7rj-2{list-style-type:none}ul.lst-kix_pnndopbxg7rj-1{list-style-type:none}ul.lst-kix_pnndopbxg7rj-0{list-style-type:none}ul.lst-kix_r2c05k5a1kzz-3{list-style-type:none}ul.lst-kix_r2c05k5a1kzz-2{list-style-type:none}.lst-kix_3urcczrnk5zr-2>li:before{content:"\0025a0   "}ul.lst-kix_r2c05k5a1kzz-1{list-style-type:none}ul.lst-kix_r2c05k5a1kzz-0{list-style-type:none}ul.lst-kix_r2c05k5a1kzz-7{list-style-type:none}ul.lst-kix_pnndopbxg7rj-8{list-style-type:none}ul.lst-kix_r2c05k5a1kzz-6{list-style-type:none}ul.lst-kix_pnndopbxg7rj-7{list-style-type:none}ul.lst-kix_r2c05k5a1kzz-5{list-style-type:none}ul.lst-kix_pnndopbxg7rj-6{list-style-type:none}ul.lst-kix_r2c05k5a1kzz-4{list-style-type:none}.lst-kix_q1k1i97sl5wh-7>li:before{content:"\0025cb   "}.lst-kix_fweaixhedeav-3>li:before{content:"\0025cf   "}.lst-kix_ohdwmula8yum-0>li:before{content:"\0025cf   "}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}.lst-kix_fweaixhedeav-7>li:before{content:"\0025cb   "}.lst-kix_41gu93x5rvez-7>li:before{content:"\0025cb   "}ol{margin:0;padding:0}table td,table th{padding:0}.c70{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c97{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c46{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#cccccc;border-bottom-style:solid}.c38{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#cccccc;border-bottom-style:solid}.c27{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#000000;border-bottom-style:solid}.c87{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c66{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#000000;border-bottom-style:solid}.c47{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#cccccc;border-bottom-style:solid}.c119{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c101{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:472.5pt;border-top-color:#000000;border-bottom-style:solid}.c99{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#000000;border-bottom-style:solid}.c115{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#cccccc;border-bottom-style:solid}.c75{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c67{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#000000;border-bottom-style:solid}.c90{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c122{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:150pt;border-top-color:#000000;border-bottom-style:solid}.c28{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c54{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c62{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c95{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c49{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:79.5pt;border-top-color:#cccccc;border-bottom-style:solid}.c118{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#cccccc;border-bottom-style:solid}.c45{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#cccccc;border-bottom-style:solid}.c117{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c60{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c98{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#cccccc;border-bottom-style:solid}.c112{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c23{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c64{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c121{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:79.5pt;border-top-color:#000000;border-bottom-style:solid}.c104{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c2{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#000000;border-bottom-style:solid}.c85{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c106{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:477pt;border-top-color:#000000;border-bottom-style:solid}.c80{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c88{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c100{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#cccccc;border-bottom-style:solid}.c94{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#000000;border-bottom-style:solid}.c20{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c63{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:79.5pt;border-top-color:#cccccc;border-bottom-style:solid}.c52{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c108{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c116{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:150pt;border-top-color:#000000;border-bottom-style:solid}.c105{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#000000;border-bottom-style:solid}.c68{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c114{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c55{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c73{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c84{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:79.5pt;border-top-color:#cccccc;border-bottom-style:solid}.c91{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#000000;border-bottom-style:solid}.c39{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:79.5pt;border-top-color:#cccccc;border-bottom-style:solid}.c7{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c81{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c76{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c19{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c82{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c109{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c3{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#000000;border-bottom-style:solid}.c36{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#000000;border-bottom-style:solid}.c124{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#000000;border-bottom-style:solid}.c102{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#000000;border-bottom-style:solid}.c40{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#000000;border-bottom-style:solid}.c44{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:261.8pt;border-top-color:#000000;border-bottom-style:solid}.c93{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:104.2pt;border-top-color:#000000;border-bottom-style:solid}.c8{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:101.2pt;border-top-color:#000000;border-bottom-style:solid}.c31{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#000000;border-bottom-style:solid}.c33{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c65{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c5{padding-top:16pt;padding-bottom:4pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c72{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c32{padding-top:18pt;padding-bottom:6pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c42{padding-top:0pt;padding-bottom:3pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c25{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c50{color:#0000ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Comic Sans MS";font-style:normal}.c92{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Arial";font-style:normal}.c58{padding-top:20pt;padding-bottom:6pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c48{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Consolas";font-style:normal}.c83{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c35{padding-top:20pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c43{color:#ff00ff;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c120{-webkit-text-decoration-skip:none;text-decoration:line-through;vertical-align:baseline;text-decoration-skip-ink:none;font-size:11pt;font-style:normal}.c30{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c18{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c78{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:center}.c10{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c21{margin-left:36pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;padding-left:0pt;text-align:left}.c126{padding-top:0pt;padding-bottom:3pt;line-height:1.5;page-break-after:avoid;text-align:left}.c127{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;text-align:left}.c41{margin-left:18pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c29{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c57{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c86{text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.c12{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:right}.c51{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c22{padding-top:0pt;padding-bottom:0pt;line-height:1.5;text-align:left}.c128{padding-top:0pt;padding-bottom:4pt;line-height:1.15;text-align:left}.c34{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c61{border-spacing:0;border-collapse:collapse;margin-right:auto}.c14{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c125{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c89{color:#ff0000;font-weight:700;font-family:"Consolas"}.c9{font-size:10pt;font-weight:700}.c113{font-weight:400;font-family:"Arial"}.c24{margin-left:72pt;padding-left:0pt}.c103{font-weight:700;font-family:"Consolas"}.c123{orphans:2;widows:2}.c37{margin-left:36pt;padding-left:0pt}.c1{padding:0;margin:0}.c26{color:inherit;text-decoration:inherit}.c53{font-weight:400;font-family:"Consolas"}.c111{margin-left:4.5pt;margin-right:-6.8pt}.c74{color:#38761d}.c79{color:#b7b7b7}.c107{color:#999999}.c96{color:#0000ff}.c11{height:11pt}.c15{font-style:italic}.c56{vertical-align:super}.c110{color:#ff0000}.c71{height:16pt}.c16{background-color:#ffff00}.c17{height:15.8pt}.c77{font-size:9pt}.c59{height:0pt}.c69{background-color:#cccccc}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c125 doc-content"><p class="c42 title" id="h.4ff09onhgxe"><span class="c92">Final Report:</span></p><p class="c123 c126 title" id="h.pdhhxk1puqj5"><span class="c92">Efficient Force Calculation for Galaxy Simulation in CUDA</span></p><p class="c18"><span class="c83">Delaynie McMillan</span></p><p class="c18"><span class="c83">Jacob Rohozen</span></p><p class="c18"><span class="c83">Tuesday, April 29, 2025</span></p><p class="c18 c11"><span class="c83"></span></p><p class="c78"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 597.00px; height: 441.76px;"><img alt="" src="images/image2.gif" style="width: 777.72px; height: 583.99px; margin-left: -99.71px; margin-top: -74.69px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h1 class="c58" id="h.4pdb0opb9drg"><span>Summary</span></h1><p class="c18"><span class="c6">For this project, we set out to implement the Barnes-Hut galaxy simulation algorithm in CUDA. Project deliverables include a highly optimized force calculation kernel written in CUDA, along with previous iterations of that kernel. We wrote a serial implementation of the algorithm, and measured and compared the performance of our different force calculation kernels. Additionally, we investigate the impact that changing the number of stars and the theta parameter has on runtime and speedup. Analysis of the serial implementation runtime showed that force calculation took up over 95% of the total runtime. Therefore, the main focus of the project was to see how we could optimize the force calculation kernel, in particular.</span></p><h1 class="c58" id="h.65pbdsh2zs97"><span class="c48">Background</span></h1><p class="c18"><span>The Barnes-Hut algorithm is an O(</span><span>nlogn</span><span class="c6">) algorithm to simulate star interaction and galaxy evolution over time. The algorithm is performed over many time steps. Time steps must be done in order, but an individual time step can be parallelized.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">The algorithm takes in arrays of data that represent all the stars in the system. Specifically, these arrays characterize the mass, initial position, and initial velocity of each star in the system. We implemented the algorithm in 2D, so the position and velocity arrays contain 2D values.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span>On each time step, the net force on each star is computed and this force results in a change in position and velocity over time. In a naive implementation, the force calculations would be O(n</span><span class="c56">2</span><span class="c6">), with n being the number of stars since each star interacts with every other star (n * (n-1)). The Barnes-Hut algorithm uses an approximation to reduce the amount of force calculations, and the algorithm becomes O(nlogn).</span></p><h2 class="c32" id="h.h78arf1nl19q"><span class="c25">The Quadtree</span></h2><p class="c18"><span class="c6">The quadtree is the main data structure for Barnes-Hut. The quadtree divides stars up based on their locations in 2D space. The root of the quadtree represents the entire system and is the bounding box for the current step in the simulation. The quadtree is built by recursively subdividing quadrants of the bounding box until every quadrant contains no more than one star. The following diagram shows a set of stars on the left and the resulting quadtree on the right.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 621.15px; height: 269.69px;"><img alt="" src="images/image14.png" style="width: 621.15px; height: 269.69px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c18"><span class="c77">Image above from </span><span class="c34 c77"><a class="c26" href="https://www.google.com/url?q=https://arborjs.org/docs/barnes-hut&amp;sa=D&amp;source=editors&amp;ust=1745923136196069&amp;usg=AOvVaw3evqPZMWSZeqJpUSNSgilG">https://arborjs.org/docs/barnes-hut</a></span><span class="c77">&nbsp;</span></p><p class="c18"><span class="c6">The gray nodes (we will call them quads) have four pointers which can either point to another quad, a star, or nothing (empty). Each quad has a center of mass and a total mass. This information represents the aggregation of all stars within the bounds of that quad.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">The operations performed on a quadtree include traversing the tree, adding a quad, and adding a star. Once the tree is fully constructed, force calculations can be performed. The benefit of the quadtree is that it allows for approximations. Instead of calculating the force on a single star from every other star, Barnes-Hut calculates the force on a single star from other quads if they are sufficiently far away.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">To add a star to the tree, the star &ldquo;starts&rdquo; at the tree&rsquo;s root. First, the algorithm determines which of the four quads at the root level the star belongs to. This is determined using the star&rsquo;s location and the center of the root quad. If there&rsquo;s already a star in that quad, the quad is further subdivided into four subquads, and the process repeats until the quad is small enough, and this star is the only star in its quad. Similarly, if it is determined that a star belongs in a certain quad, and that quad is already subdivided into smaller quads, we &ldquo;follow&rdquo; that quad until we arrive at an &ldquo;empty&rdquo; quad with no star. Below are illustrations of adding a star to an empty quad, and sub-dividing a quad before inserting a star.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c78"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 551.50px; height: 304.62px;"><img alt="" src="images/image4.png" style="width: 551.50px; height: 304.62px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c78"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 550.00px; height: 310.31px;"><img alt="" src="images/image9.png" style="width: 550.00px; height: 310.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c32" id="h.xok0gfcr89nn"><span class="c25">Force Calculations</span></h2><p class="c18"><span class="c6">Even though the Barnes-Hut approximation reduces the algorithmic complexity to O(nlogn), the force calculations part of the algorithm still takes more than 95% of the total runtime for a serial implementation. This is why we decided to optimize the force calculations.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">At first glance, there is plenty of work that can be done in parallel. The net force on each star can be independently calculated, and the quadtree is not modified (only read) in this step. This means that no synchronization or atomics are needed for correctness. The same arithmetic steps are being done on large quantities of stars to calculate the net forces on them, which would be a great use of SIMD parallelism. This sounds good, but the Barnes-Hut algorithm maps poorly to GPU execution.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">One problem is that force calculation has low arithmetic intensity. Another problem is that traversing the tree is highly irregular, and this leads to poor locality. Traversing a tree requires accessing a lot of different portions of the quadtree data structure, which results in poor cache locality, especially when one block has threads whose working sets of data do not overlap much. When implemented naively, these problems lead to the algorithm being bandwidth-limited because of poor data reuse. Because of this, our project involved figuring out ways to take advantage of shared memory between threads to reduce memory bandwidth requirements.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">Additionally, the irregular nature of the tree causes another problem: thread divergence. In CUDA, all 32 threads in a warp execute in lockstep. When a warp is traversing a tree some threads will finish before others. Even if only one thread is still traversing the tree, all the other threads will sit idle and wait. Thread divergence reduces the efficiency of the GPU, leading to lower overall throughput.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">Furthermore, the recursive nature of the Barnes-Hut algorithm maps poorly to the CUDA model.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">A later section will discuss our approach to Barnes-Hut and making the force calculations step more amenable to GPU execution.</span></p><h1 class="c58" id="h.dm4qpi5x7iv5"><span class="c48">Approach</span></h1><p class="c18"><span class="c6">We started by implementing a serial Barnes-Hut algorithm in C++. This served to verify our parallel implementation as we built it up, and we also used the serial code as a benchmark for speedup comparison. The serial implementation had classes and methods for manipulating stars and quads. We did not spend time optimizing the serial version, but we don&rsquo;t feel that it is unreasonably slow (as this would make for an unfair comparison). The serial code was run on the GHC machines.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">We developed a class called Galaxy to randomly generate inputs for both the serial and the CUDA implementations. Galaxies can be made from a customizable size and customizable number of stars orbiting a central supermassive black hole (just another star with a lot more mass). A galaxy can be given an initial position and an initial velocity. This is how we generate multiple galaxies and have them collide. The results of the simulation can be seen using our Python visualizer, and it can output a gif of the simulation also.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">Our parallel implementation is written in CUDA and was also run on the GHC machines, specifically on the NVIDIA GeForce RTX 2080 GPUs. These GPUs have 46 streaming multiprocessors, and this helped inform our kernel launches.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">The first part of making an efficient GPU implementation was changing our data structures.</span></p><h2 class="c32" id="h.mx0lkspdxp86"><span class="c25">Rethinking our Data Structures</span></h2><p class="c18"><span class="c6">In our serial implementation, we used classes for stars and quads and pointers to objects to manipulate class fields. This required dynamically allocating memory for quads and later freeing that memory on every timestep because the quadtree must be rebuilt from updated star positions.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">For our parallel implementation, we chose a more primitive data structure scheme as that gave us more explicit control over data locality. We used arrays, and this approach allowed us to allocate all memory only once for an entire simulation. This saves a lot of time that would otherwise be spent dynamically allocating memory on each timestep.</span></p><h3 class="c5" id="h.vrrktlmsly2j"><span class="c72">Stars and Individual Quads</span></h3><p class="c18"><span class="c6">Drawing inspiration from Burtscher and Pingali&rsquo;s paper, we broke our star and quad class properties into separate arrays. For example, instead of using a single array to hold all stars objects, we used one array for each property of the star (mass, position, velocity, force). Additionally, we have a separate array that keeps &nbsp;track of the location of the quads&rsquo; sub-quads. </span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">For properties that both stars and quads share (i.e. mass and center of mass), we extended the arrays to make space to hold quad properties as well. Since arrays are now shared between stars and quads, we placed star indexes at the front of the array and quad indexes at the end of the array.</span></p><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 142.67px;"><img alt="" src="images/image16.png" style="width: 624.00px; height: 142.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c5" id="h.98zcxcmtztxq"><span class="c72">The Quadtree</span></h3><p class="c18"><span class="c6">The data structure for representing the entire quadtree is an array of integers, the quads array. The quads array is basically an array of indexes of quads or stars. Instead of using pointers to objects in memory, we use array indexes that &ldquo;point to&rdquo; other parts of the array. </span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span>We allocate one quad for each star in the system, and each quad requires four integers (its four children). Since some of the arrays (mass and position) contain star and quad values, the quads array grows from the back towards the front as more quads are used. In summary we allocate (quad_limit = 2 </span><img src="images/image1.png"><span>&nbsp;num_stars) quads for the quads array. Then the number of integers allocated is 4 </span><img src="images/image1.png"><span class="c6">&nbsp;quad_limit. The following image shows how our data structures are arranged. </span></p><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 353.33px;"><img alt="" src="images/image7.png" style="width: 624.00px; height: 353.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 337.33px;"><img alt="" src="images/image15.png" style="width: 624.00px; height: 337.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c6">Stars in the simulation will be divided among all the threads launched in the tree build kernel. To be more specific, each thread will be responsible for adding a certain number of stars to the quadtree. Building the quadtree involves adding stars one by one, each time starting at the root of the quadtree (the root&rsquo;s quad index is quad_limit - 1). Adding a star to any quad is similar to the serial implementation with additional steps for handling locks and atomics to ensure correctness. When one thread wants to insert either a star or more quads into an empty quad, atomic CAS is used to ensure that only one thread can successfully modify a single part of the tree at once.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">Locks are necessary when updating the tree requires more than changing (swapping) a single value. This occurs when attempting to add a star to a quadrant already containing a star because this requires shuffling around some values. Before inserting our current star, we must &ldquo;demote&rdquo; the star that&rsquo;s already in the quad, and keep &ldquo;demoting&rdquo; it until the quads are small enough such that both stars are in their own quad. In this case, the thread will attempt to acquire the lock by using atomic CAS to swap the current value (the other star&rsquo;s index) with -2, signifying to other threads that the position is locked. </span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">Since changes only occur at the leaf values of the quadtree (at stars or empty quadrants), we reduced the granularity of our locks to only child values (not entire quads). This allows other threads to make progress if they are not attempting to modify the same position.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">The states maintained outside of the while loop for inserting a new quad are: the coordinates of the current quad we are trying to insert into, size of said quad, the index of that quad, and the tree depth. State is maintained so that should a CAS for inserting a star or locking a quad fail, the loop restarts and does not have to traverse the entire tree up to that point again. It simply resumes at the index and depth where it left off, once again reading the child value it is attempting to modify, casing on that value, and repeating until success.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span>While developing a scheme for building the quadtree, we drew a lot of inspiration from Burtscher and Pingali&rsquo;s CUDA code for the Barnes-Hut algorithm. This helped us begin reasoning about the benefits and limitations of interacting with a tree using a GPU. The pseudocode for inserting stars is below:</span></p><p class="c10 c11"><span class="c4"></span></p><p class="c30"><span class="c86 c53 c79">// assume s1 is the star to be added</span></p><p class="c30"><span class="c4">while (more stars to add) {</span></p><p class="c30"><span class="c4">&nbsp; if (first time attempting to add star to tree) {</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; set current quad to root</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; find which of root&rsquo;s children the star will follow</span></p><p class="c30"><span class="c4">&nbsp; }</span></p><p class="c30"><span class="c4">&nbsp; get child value of current quad</span></p><p class="c30"><span class="c4">&nbsp; while (child is not a quad) {</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; traverse the tree</span></p><p class="c30"><span class="c4">&nbsp; }</span></p><p class="c30"><span class="c53">&nbsp; </span><span class="c53 c79">// child is not a quad: could be a </span><span class="c53 c96">star</span><span class="c53 c79">,</span><span class="c53">&nbsp;</span><span class="c53 c74">empty</span><span class="c53 c79">, or </span><span class="c86 c53 c110">locked</span></p><p class="c30"><span class="c53">&nbsp; if (child is </span><span class="c53 c110">locked</span><span class="c4">) {</span></p><p class="c30"><span class="c53">&nbsp; &nbsp; </span><span class="c86 c53 c79">// can&rsquo;t do anything</span></p><p class="c30"><span class="c53">&nbsp; } else if (child is </span><span class="c53 c74">empty</span><span class="c4">) {</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; attempt to replace empty value with star value (atomic CAS)</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; if (atomic CAS successful) {</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; &nbsp; Move on to next star</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; }</span></p><p class="c30"><span class="c53">&nbsp; } else { </span><span class="c53 c79">// child is a</span><span class="c53">&nbsp;</span><span class="c86 c53 c96">star</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; attempt to lock (atomic CAS)</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; if (lock acquired) {</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; &nbsp; s2 = child value</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; &nbsp; do {</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;allocate&quot; space for a new quad using atomicSub</span></p><p class="c30"><span class="c53">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c53 c79 c86">// for new quad</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; determine which quadrant s1 and s2 should be added to</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (stars occupy separate quadrants) {</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; add stars to their respective quadrant</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {</span></p><p class="c30"><span class="c53">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; move on </span><span class="c86 c53 c107">// need to try again for newly allocated quad</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; &nbsp; } while (s1 and s2 in same quad)</span></p><p class="c30"><span class="c4">&nbsp; &nbsp; }</span></p><p class="c30"><span class="c4">&nbsp; }</span></p><p class="c30"><span class="c53">&nbsp; __threadfence() </span><span class="c86 c53 c107">// ensures update has completed before releasing lock</span></p><p class="c30"><span class="c4">&nbsp; if (lock held) {</span></p><p class="c30"><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;release lock</span></p><p class="c30"><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;put correct quad value back</span></p><p class="c30"><span class="c53">&nbsp; &nbsp; &nbsp; </span><span class="c86 c53 c79">// -2 is the lock value (not a valid quad index)</span></p><p class="c30"><span class="c4">&nbsp; }</span></p><p class="c30"><span class="c4">}</span></p><h2 class="c32" id="h.5dwmeknw5aoa"><span class="c25">The Force Calculations Kernel</span></h2><p class="c18"><span class="c6">The design of the force calculations kernel was refined over many iterations. Along the way, we used the C++ chrono library to determine wall clock runtime and used the NVIDIA Nsight profiler to determine what we needed to optimize next.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">Since recursion is not well-suited for GPU execution, our implementation uses a stack to traverse the quadtree. The stack is an array of integers, and it tracks which child value to look at next. We defined the maximum depth of the stack to be 32. This allowed us to statically allocate the stack, but also required us to limit the maximum depth when building the quadtree. A maximum depth of 32 still allows for a large quadtree with many levels.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">The overall idea for each implementation is to statically assign stars to threads, and each thread computes the net force on each of its stars. The problem with statically assigning stars is that it results in bad load balancing. This is because the amount of work needed to calculate the net force on a star varies significantly depending on the star&rsquo;s location, and not only is the amount of work not known at assignment time, it changes every timestep.</span></p><h3 class="c5" id="h.ljw7y26t1jn3"><span class="c72">Force Calculation Attempt #1</span></h3><p class="c18"><span class="c6">In the first implementation of the kernel, each thread had a stack all to itself, and each level of the stack had four spots to put child values. A -1 would represent an empty position in the stack. We launched this kernel with many blocks and 1024 threads per block. The pseudocode for this implementation follows.</span></p><p class="c10 c11"><span class="c4"></span></p><p class="c10"><span class="c4">// note that push and pop take a level argument</span></p><p class="c10"><span class="c4">depth = 0</span></p><p class="c10"><span class="c4">push(root, depth)</span></p><p class="c10"><span class="c4">while (stack is not empty) {</span></p><p class="c10"><span class="c4">&nbsp; child_val = pop(depth)</span></p><p class="c10"><span class="c4">&nbsp; if (child_val == -1) {</span></p><p class="c10"><span class="c4">&nbsp; &nbsp; // nothing to do</span></p><p class="c10"><span class="c4">&nbsp; } else if (child is a star) {</span></p><p class="c10"><span class="c4">&nbsp; &nbsp; // interact with this star</span></p><p class="c10"><span class="c4">&nbsp; &nbsp; Calculate force from other star</span></p><p class="c10"><span class="c4">&nbsp; } else if (child is a quad) {</span></p><p class="c10"><span class="c4">&nbsp; &nbsp; if (far enough away) {</span></p><p class="c10"><span class="c4">&nbsp; &nbsp; &nbsp; Calculate force from quad</span></p><p class="c10"><span class="c4">&nbsp; &nbsp; } else {</span></p><p class="c10"><span class="c4">&nbsp; &nbsp; &nbsp; depth++</span></p><p class="c10"><span class="c4">&nbsp; &nbsp; &nbsp; push all the quad&rsquo;s children onto stack // level has been incremented</span></p><p class="c10"><span class="c4">&nbsp; &nbsp; }</span></p><p class="c10"><span class="c4">&nbsp; }</span></p><p class="c10"><span class="c4">&nbsp; if (level is empty) {</span></p><p class="c10"><span class="c4">&nbsp; &nbsp; depth--</span></p><p class="c10"><span class="c4">&nbsp; }</span></p><p class="c10"><span class="c4">}</span></p><p class="c10 c11"><span class="c4"></span></p><p class="c18"><span class="c6">There are multiple performance problems with this initial implementation. Below is the part of the Nsight profile output for the force kernel.</span></p><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 606.50px; height: 79.11px;"><img alt="" src="images/image13.png" style="width: 606.50px; height: 79.11px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">As you can see, we had a very significant DRAM bottleneck. This is because force calculation has a low arithmetic intensity and there is no memory reuse in this implementation.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">This implementation also suffers from thread divergence as thread work depends significantly on the locations of the stars.</span></p><h3 class="c5" id="h.233o8q2uz03l"><span class="c72">Force Calculation Attempt #2</span></h3><p class="c10"><span class="c6">The first improvement to the original kernel involved sharing the stack. We realized that since every thread in a warp executes instructions in lockstep, it makes sense for each thread in a warp to share the same stack. This means that each thread in the warp traverses the same part of the tree at the same time, so memory accesses are coalesced. This helps reduce memory bandwidth use because each thread can make use of the same memory.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">To get this new design to work, we reduced the block size to 32 (the number of threads in a warp) and allocated a shared stack for each block (warp). Additionally, the stack was modified to only push one child value at a time, instead of all four,.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">Each block has a &ldquo;stack manager&rdquo; (thread 0 in the block) that manipulates the stack for the rest of the threads. At the beginning, the stack manager also precomputes and saves values that depend only on depth in another shared array to avoid computation later.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span>Since each thread in the warp shares the stack, we needed a way to determine if the warp should compute forces on its stars from a quad or continue traversing the quad&rsquo;s children. The CUDA warp-level function </span><span class="c53">__anysync</span><span class="c6">&nbsp;solved this problem by allowing any thread that needed to continue to force the other threads in the warp to continue.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c18"><span>An interesting outcome is that using </span><span class="c53">__anysync</span><span class="c6">&nbsp;results in the algorithm being slightly more accurate. Suppose one thread (we shall refer to as Thread 1) determines that a quad was far enough away from its own star, but another thread (referred to as Thread 2) determines that this same quad is not far enough away. Therefore, Thread 2 must continue traversing the tree at this particular point, while Thread 1 does not. However, it does not benefit Thread 1 to stop traversing the tree and instead use this quad&rsquo;s aggregate values to calculate the force on its star because Thread 1 still has to wait on all the other threads that continue to traverse the tree. Furthermore, this would lead to a worse approximation of the star system because continuing down the quadtree is more accurate, and all threads in the warp must continue anyway. For this kernel design, this leads to a better approximation at no additional cost.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">The resulting Nsight profile shows that the compute throughput increased and memory throughput decreased, as intended.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.50px; height: 101.18px;"><img alt="" src="images/image17.png" style="width: 600.50px; height: 101.18px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c123 c127" id="h.de28fb2u8f7l"><span class="c72">Force Calculation Attempt #3</span></h3><p class="c18"><span class="c6">The next optimization for force calculation involved introducing another kernel - a sorting kernel. Sorting occurred before the force calculation kernel, and the output of the sort is an inorder traversal of the quadtree. We implemented this kernel serially, so the kernel itself is not very interesting. However, the sorting is crucial for the force calculation kernel. The inorder traversal results in stars that are nearby in space being nearby in the resulting array.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">Since threads in the warp now calculate forces for stars that are closer together, there is significantly less thread divergence because each thread needs to traverse similar parts of the quadtree, and this results in a substantial speedup. Final speedup values and analysis are available in the results section.</span></p><h3 class="c5" id="h.fzq48295gr4w"><span class="c72">Force Kernel Launch Configuration</span></h3><p class="c10"><span>Our final design limited us to using a block size of 32 for our kernel launch. We determined the number of blocks to launch empirically by sweeping over this value and comparing kernel runtimes. The final launch configuration was 46 </span><img src="images/image1.png"><span class="c6">&nbsp;8 = 368 blocks. The value 46 is significant because it is the number of streaming multiprocessors on a GeForce RTX 2080.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c123 c128"><span class="c6">Unfortunately, our final design had poor occupancy. Occupancy is the ratio of the number of active warps per multiprocessor to the maximum number of possible active warps.</span></p><p class="c0 c123"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 569.50px; height: 73.36px;"><img alt="" src="images/image3.png" style="width: 569.50px; height: 73.36px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c10"><span class="c6">Increasing the block size would result in better occupancy because there would be more warps per block, and the theoretical occupancy is limited by the number of blocks. In our current implementation, this is not possible because the stack is only designed for a single warp.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">Given more time, we would have improved our stack to work with more warps, enabling us to increase the block size. In this scenario, the shared stack would be &ldquo;wider,&rdquo; but each warp&rsquo;s respective stack manager would only manipulate the part of the stack corresponding to its warp.</span></p><h1 class="c58" id="h.en9c85q8njz6"><span class="c48">Results</span></h1><p class="c18"><span class="c6">In addition to results and approaches listed above, we also took performance measurements of our final implementation, and how they are affected by problem size. Specifically, we investigated this implementation&rsquo;s sensitivity to star count and the theta parameter.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">We were most concerned with optimizing the force calculation step as this took the longest time to compute serially. We were less concerned with the overall speedup of the entire algorithm because not all of our kernels were optimized. In fact, the sorting kernel is executed serially. This would tend to reduce our overall performance and also cause us to underestimate the percentage of time spent on the force calculation kernel (compared to a parallel sort). Still, we achieve a significant speedup over our sequential implementation. If we had more time, we would implement a parallel sorting kernel.</span></p><h2 class="c32" id="h.78jnusmk0552"><span class="c25">Force Calculation Sensitivity to Star Count</span></h2><p class="c18"><span class="c6">We measured the impact that the number of stars has on force calculation time as well as total runtime for both our CUDA implementation and our serial implementation. To maintain consistency, all tests (both ones run on the CPU and GPU) were given the same seed for randomness. This ensures consistency in the initial star positions across tests. Additionally, all tests were run with a timestep size of 0.0001 years, computing 60 time steps, with a theta value of 0.2. Below are the results from experiments using 100-1,000,000 stars.</span></p><p class="c18 c11"><span class="c6"></span></p><table class="c61"><tr class="c17"><td class="c101" colspan="4" rowspan="1"><p class="c51"><span class="c9 c15">Serial Runtime vs Star Count</span></p></td></tr><tr class="c17"><td class="c39" colspan="1" rowspan="1"><p class="c57"><span class="c9">Stars</span></p></td><td class="c98" colspan="1" rowspan="1"><p class="c57"><span class="c9">Force Calculation Time (s)</span></p></td><td class="c47" colspan="1" rowspan="1"><p class="c57 c111"><span class="c9">Total Runtime (s)</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c57"><span class="c9">Force Calculation Percent of Total Time</span></p></td></tr><tr class="c17"><td class="c121" colspan="1" rowspan="1"><p class="c12"><span class="c13">100</span></p></td><td class="c94" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.0070</span></p></td><td class="c91" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.0081</span></p></td><td class="c2" colspan="1" rowspan="1"><p class="c12"><span class="c13">85.9117%</span></p></td></tr><tr class="c17"><td class="c63" colspan="1" rowspan="1"><p class="c12"><span class="c13">1,000</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.3541</span></p></td><td class="c45" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.3650</span></p></td><td class="c62" colspan="1" rowspan="1"><p class="c12"><span class="c13">97.0243%</span></p></td></tr><tr class="c17"><td class="c49" colspan="1" rowspan="1"><p class="c12"><span class="c13">10,000</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c12"><span class="c13">7.9880</span></p></td><td class="c100" colspan="1" rowspan="1"><p class="c12"><span class="c13">8.0994</span></p></td><td class="c119" colspan="1" rowspan="1"><p class="c12"><span class="c13">98.6239%</span></p></td></tr><tr class="c17"><td class="c63" colspan="1" rowspan="1"><p class="c12"><span class="c13">100,000</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c12"><span class="c13">141.8995</span></p></td><td class="c45" colspan="1" rowspan="1"><p class="c12"><span class="c13">143.6660</span></p></td><td class="c62" colspan="1" rowspan="1"><p class="c12"><span class="c13">98.7704%</span></p></td></tr><tr class="c17"><td class="c84" colspan="1" rowspan="1"><p class="c12"><span class="c13">1,000,000</span></p></td><td class="c118" colspan="1" rowspan="1"><p class="c12"><span class="c13">3090.7263</span></p></td><td class="c115" colspan="1" rowspan="1"><p class="c12"><span class="c13">3121.5092</span></p></td><td class="c117" colspan="1" rowspan="1"><p class="c12"><span class="c13">99.0138%</span></p></td></tr></table><p class="c18 c11"><span class="c6"></span></p><table class="c61"><tr class="c17"><td class="c101" colspan="4" rowspan="1"><p class="c51"><span class="c9 c15">CUDA Runtime vs Star Count</span></p></td></tr><tr class="c17"><td class="c39" colspan="1" rowspan="1"><p class="c57"><span class="c9">Stars</span></p></td><td class="c98" colspan="1" rowspan="1"><p class="c57"><span class="c9">Force Calculation Time (s)</span></p></td><td class="c47" colspan="1" rowspan="1"><p class="c57 c111"><span class="c9">Total Runtime (s)</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c57"><span class="c9">Force Calculation Percent of Total Time</span></p></td></tr><tr class="c17"><td class="c121" colspan="1" rowspan="1"><p class="c12"><span class="c13">100</span></p></td><td class="c94" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.0044</span></p></td><td class="c91" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.1081</span></p></td><td class="c2" colspan="1" rowspan="1"><p class="c12"><span class="c13">4.0835%</span></p></td></tr><tr class="c17"><td class="c63" colspan="1" rowspan="1"><p class="c12"><span class="c13">1,000</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.0219</span></p></td><td class="c45" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.1484</span></p></td><td class="c62" colspan="1" rowspan="1"><p class="c12"><span class="c13">14.7334%</span></p></td></tr><tr class="c17"><td class="c49" colspan="1" rowspan="1"><p class="c12"><span class="c13">10,000</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.3179</span></p></td><td class="c100" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.6404</span></p></td><td class="c119" colspan="1" rowspan="1"><p class="c12"><span class="c13">49.6382%</span></p></td></tr><tr class="c17"><td class="c63" colspan="1" rowspan="1"><p class="c12"><span class="c13">100,000</span></p></td><td class="c38" colspan="1" rowspan="1"><p class="c12"><span class="c13">4.5898</span></p></td><td class="c45" colspan="1" rowspan="1"><p class="c12"><span class="c13">7.0570</span></p></td><td class="c62" colspan="1" rowspan="1"><p class="c12"><span class="c13">65.0385%</span></p></td></tr><tr class="c17"><td class="c84" colspan="1" rowspan="1"><p class="c12"><span class="c13">1,000,000</span></p></td><td class="c118" colspan="1" rowspan="1"><p class="c12"><span class="c13">68.7030</span></p></td><td class="c115" colspan="1" rowspan="1"><p class="c12"><span class="c13">96.2523</span></p></td><td class="c117" colspan="1" rowspan="1"><p class="c12"><span class="c13">71.3780%</span></p></td></tr></table><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 308.00px;"><img alt="" src="images/image10.png" style="width: 624.00px; height: 308.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 308.00px;"><img alt="" src="images/image6.png" style="width: 624.00px; height: 308.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c18"><span class="c6">The results above demonstrate that, as one would expect, increasing star count increases runtime. Our implementation exhibits good speedup compared to our serial implementation for large amounts of stars. In practice, it doesn&rsquo;t make sense to use small amounts of stars on GPUs since they can launch thousands of threads.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">We found it interesting that on a log scale for both time and star count, the CUDA implementation and serial implementation had very similar slopes&ndash;they were just offset by a consistent factor of 10.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">We also looked at the impact that star count has on the speedup of our force calculation kernel. We found a clear trend where the speedup increases as the number of stars (aka the problem size) increases. Our implementation was able to reach up to a 44.9x speedup at 1,000,000 stars. Although there are some difficulties when running an algorithm that&rsquo;s rather recursive and non-uniform on a GPU, the high quantity of cores and SIMD parallelism makes these tradeoffs worth it, especially for large problem sizes. It is definitely viable to do Barnes-Hut on a GPU, provided the algorithm is optimized enough. Below is a table and a graph of our data.</span></p><p class="c18 c11"><span class="c6"></span></p><table class="c61"><tr class="c17"><td class="c122" colspan="2" rowspan="1"><p class="c0"><span class="c9 c15">Force Calculation Speedup</span></p></td></tr><tr class="c17"><td class="c19" colspan="1" rowspan="1"><p class="c29"><span class="c9">Stars</span></p></td><td class="c85" colspan="1" rowspan="1"><p class="c29"><span class="c9">Speedup</span></p></td></tr><tr class="c17"><td class="c67" colspan="1" rowspan="1"><p class="c14"><span class="c13">100</span></p></td><td class="c99" colspan="1" rowspan="1"><p class="c14"><span class="c13">1.5774</span></p></td></tr><tr class="c17"><td class="c95" colspan="1" rowspan="1"><p class="c14"><span class="c13">1,000</span></p></td><td class="c80" colspan="1" rowspan="1"><p class="c14"><span class="c13">16.1950</span></p></td></tr><tr class="c17"><td class="c109" colspan="1" rowspan="1"><p class="c14"><span class="c13">10,000</span></p></td><td class="c112" colspan="1" rowspan="1"><p class="c14"><span class="c13">25.1280</span></p></td></tr><tr class="c17"><td class="c95" colspan="1" rowspan="1"><p class="c14"><span class="c13">100,000</span></p></td><td class="c80" colspan="1" rowspan="1"><p class="c14"><span class="c13">30.9164</span></p></td></tr><tr class="c17"><td class="c23" colspan="1" rowspan="1"><p class="c14"><span class="c13">1,000,000</span></p></td><td class="c64" colspan="1" rowspan="1"><p class="c14"><span class="c13">44.9868</span></p></td></tr></table><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 386.67px;"><img alt="" src="images/image11.png" style="width: 624.00px; height: 386.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><h2 class="c32" id="h.lo1oulksp7wv"><span class="c25">Limits to Speedup</span></h2><p class="c18"><span class="c6">The main limitations to speedup are thread divergence, memory bandwidth, and inefficient use of the GPU streaming multiprocessors. Not every thread in a warp is always doing &ldquo;useful&rdquo; work. For example, all threads in a warp traverse all parts of the tree that only a subset of threads actually need to traverse. In this situation, the other threads in that warp could have just used aggregate calculations if they didn&rsquo;t have to continue executing in lockstep. Since our implementation does not explicitly disable these threads, the Nsight profiler will report them as doing work, but in actuality they could have been doing something more useful for the progress of the simulation (such as calculating forces on another star).</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">As discussed in earlier sections, force calculation has low arithmetic intensity. We increased memory reuse in the force calculation kernel, and this helped speedup, but it is still a limiting factor. The following Nsight output shows our final values for throughput.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 97.33px;"><img alt="" src="images/image8.png" style="width: 624.00px; height: 97.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">Finally, our implementation is limited by poor SM occupancy. As discussed in earlier sections, occupancy relates to the number of active warps. Our stack implementation limited our block size to 32 (the size of one warp), and this reduced our maximum possible occupancy. The Nsight output is repeated again here for convenience.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 622.51px; height: 77.96px;"><img alt="" src="images/image3.png" style="width: 622.51px; height: 77.96px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c32" id="h.ukzze432k8zs"><span class="c25">Force Calculation Sensitivity to Theta Parameter</span></h2><p class="c18"><span>When computing the net force on a star exerted by the other stars in this system, the N-body O(n</span><span class="c56">2</span><span class="c6">) problem becomes an O(nlogn) problem due to the fact that a star cluster that is sufficiently far away from another star can be approximated as a single body exerting a force on that star.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span>The theta parameter is what is used to decide whether or not a quad is sufficiently far away from a given star and is sufficiently small enough. Given a star and a quad, if the side length of the quad divided by the distance between the star and the center of the quad is less than theta, then that star will treat that quad as an aggregate body exerting some force on it. Should the quotient </span><span class="c15">not</span><span class="c6">&nbsp;be less than theta, then the same process is repeated with quad&rsquo;s sub-quads, until the quotient is less than theta or the quad&rsquo;s child is a star.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">Similar to the previous experiment, all tests were given the same seed for randomness, a timestep size of 0.0001 years, computing 60 time steps, with a star count of 1,000 stars. Below are the results for values of theta ranging from 0.10 to 0.40.</span></p><p class="c18 c11"><span class="c6"></span></p><table class="c61"><tr class="c71"><td class="c106" colspan="4" rowspan="1"><p class="c51"><span class="c9 c15">Serial Runtime (in seconds) vs Theta Value</span></p></td></tr><tr class="c71"><td class="c104" colspan="1" rowspan="1"><p class="c57"><span class="c9">Theta</span></p></td><td class="c81" colspan="1" rowspan="1"><p class="c57"><span class="c9">Force Calc</span></p></td><td class="c114" colspan="1" rowspan="1"><p class="c57"><span class="c9">Total</span></p></td><td class="c87" colspan="1" rowspan="1"><p class="c57"><span class="c9">Percentage</span></p></td></tr><tr class="c71"><td class="c105" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.10</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.5743</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.5836</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c12"><span class="c13">98.3970%</span></p></td></tr><tr class="c71"><td class="c52" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.15</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.4154</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.4247</span></p></td><td class="c88" colspan="1" rowspan="1"><p class="c12"><span class="c13">97.8124%</span></p></td></tr><tr class="c71"><td class="c76" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.20</span></p></td><td class="c54" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.3216</span></p></td><td class="c97" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.3319</span></p></td><td class="c75" colspan="1" rowspan="1"><p class="c12"><span class="c13">96.8777%</span></p></td></tr><tr class="c71"><td class="c52" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.25</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.2483</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.2579</span></p></td><td class="c88" colspan="1" rowspan="1"><p class="c12"><span class="c13">96.2422%</span></p></td></tr><tr class="c71"><td class="c76" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.30</span></p></td><td class="c54" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.2059</span></p></td><td class="c97" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.2156</span></p></td><td class="c75" colspan="1" rowspan="1"><p class="c12"><span class="c13">95.5192%</span></p></td></tr><tr class="c71"><td class="c52" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.35</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.1710</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.1806</span></p></td><td class="c88" colspan="1" rowspan="1"><p class="c12"><span class="c13">94.7004%</span></p></td></tr><tr class="c71"><td class="c73" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.40</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.1504</span></p></td><td class="c90" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.1599</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c12"><span class="c13">94.0419%</span></p></td></tr></table><p class="c18 c11"><span class="c6"></span></p><table class="c61"><tr class="c17"><td class="c106" colspan="4" rowspan="1"><p class="c51"><span class="c9 c15">CUDA Runtime (in seconds) vs Theta Value</span></p></td></tr><tr class="c71"><td class="c104" colspan="1" rowspan="1"><p class="c57"><span class="c9">Theta</span></p></td><td class="c81" colspan="1" rowspan="1"><p class="c57"><span class="c9">Force Calc</span></p></td><td class="c114" colspan="1" rowspan="1"><p class="c57"><span class="c9">Total</span></p></td><td class="c87" colspan="1" rowspan="1"><p class="c57"><span class="c9">Percentage</span></p></td></tr><tr class="c71"><td class="c105" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.10</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.0262</span></p></td><td class="c3" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.1418</span></p></td><td class="c66" colspan="1" rowspan="1"><p class="c12"><span class="c13">18.4882%</span></p></td></tr><tr class="c71"><td class="c52" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.15</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.0226</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.1105</span></p></td><td class="c88" colspan="1" rowspan="1"><p class="c12"><span class="c13">20.4782%</span></p></td></tr><tr class="c71"><td class="c76" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.20</span></p></td><td class="c54" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.0201</span></p></td><td class="c97" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.1219</span></p></td><td class="c75" colspan="1" rowspan="1"><p class="c12"><span class="c13">16.4496%</span></p></td></tr><tr class="c71"><td class="c52" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.25</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.0176</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.1014</span></p></td><td class="c88" colspan="1" rowspan="1"><p class="c12"><span class="c13">17.3407%</span></p></td></tr><tr class="c71"><td class="c76" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.30</span></p></td><td class="c54" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.0153</span></p></td><td class="c97" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.0993</span></p></td><td class="c75" colspan="1" rowspan="1"><p class="c12"><span class="c13">15.4262%</span></p></td></tr><tr class="c71"><td class="c52" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.35</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.01388</span></p></td><td class="c20" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.12502</span></p></td><td class="c88" colspan="1" rowspan="1"><p class="c12"><span class="c13">11.1018%</span></p></td></tr><tr class="c71"><td class="c73" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.40</span></p></td><td class="c7" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.01246</span></p></td><td class="c90" colspan="1" rowspan="1"><p class="c12"><span class="c13">0.11302</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c12"><span class="c13">11.0289%</span></p></td></tr></table><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 308.00px;"><img alt="" src="images/image5.png" style="width: 624.00px; height: 308.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c18"><span class="c6">As one would expect, increasing theta (effectively decreasing problem size) decreases overall runtime for both the CUDA and serial implementations. With the serial implementation, there is a strong, exponential downward trend on the time vs theta value graph. The speedup also gets worse because at smaller problem sizes, the CUDA implementation has more overhead to deal with, relative to the actual force calculations that are happening. Not only that, since there are more threads deciding that they don&rsquo;t need to further traverse the tree, the amount of necessary work being done is also decreasing. Overall, fewer threads are deeming it necessary to traverse the tree further. Below is the speedup data we collected, depicting a downwards trend as theta increases.</span></p><p class="c18 c11"><span class="c43 c16"></span></p><table class="c61"><tr class="c17"><td class="c116" colspan="2" rowspan="1"><p class="c0"><span class="c9 c15">Force Calculation Speedup</span></p></td></tr><tr class="c17"><td class="c82" colspan="1" rowspan="1"><p class="c0"><span class="c9">Theta</span></p></td><td class="c108" colspan="1" rowspan="1"><p class="c0"><span class="c9">Speedup</span></p></td></tr><tr class="c17"><td class="c67" colspan="1" rowspan="1"><p class="c0"><span class="c13">0.10</span></p></td><td class="c99" colspan="1" rowspan="1"><p class="c0"><span class="c13">21.89972455</span></p></td></tr><tr class="c17"><td class="c60" colspan="1" rowspan="1"><p class="c0"><span class="c13">0.15</span></p></td><td class="c68" colspan="1" rowspan="1"><p class="c0"><span class="c13">18.34834341</span></p></td></tr><tr class="c17"><td class="c109" colspan="1" rowspan="1"><p class="c0"><span class="c13">0.20</span></p></td><td class="c112" colspan="1" rowspan="1"><p class="c0"><span class="c13">16.03389539</span></p></td></tr><tr class="c17"><td class="c60" colspan="1" rowspan="1"><p class="c0"><span class="c13">0.25</span></p></td><td class="c68" colspan="1" rowspan="1"><p class="c0"><span class="c13">14.11259068</span></p></td></tr><tr class="c17"><td class="c109" colspan="1" rowspan="1"><p class="c0"><span class="c13">0.30</span></p></td><td class="c112" colspan="1" rowspan="1"><p class="c0"><span class="c13">13.44601996</span></p></td></tr><tr class="c17"><td class="c60" colspan="1" rowspan="1"><p class="c0"><span class="c13">0.35</span></p></td><td class="c68" colspan="1" rowspan="1"><p class="c0"><span class="c13">12.3206768</span></p></td></tr><tr class="c17"><td class="c23" colspan="1" rowspan="1"><p class="c0"><span class="c13">0.40</span></p></td><td class="c64" colspan="1" rowspan="1"><p class="c0"><span class="c13">12.06294906</span></p></td></tr></table><p class="c18 c11"><span class="c43 c16"></span></p><p class="c18 c11"><span class="c16 c43"></span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 385.33px;"><img alt="" src="images/image12.png" style="width: 624.00px; height: 385.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c18"><span class="c6">Overall, we were pleased with our final implementation and performance results. We showed that an optimized GPU kernel for force calculation is a viable method to implement Barnes-Hut in parallel, with speedup increasing drastically as problem size increases.</span></p><h1 class="c58" id="h.sgopuwkacvek"><span class="c48">Next Steps</span></h1><p class="c18"><span class="c6">In our undertaking of this project, we set out to build and optimize a Barnes-Hut implementation in CUDA. Based on our findings while writing and testing this code, we are still left with ideas on how to further improve our implementation, along with some more questions about the effects certain changes could have on our performance.</span></p><p class="c18 c11"><span class="c6"></span></p><p class="c18"><span class="c6">If we had more time, we would like to:</span></p><ul class="c1 lst-kix_49l6hhcwk3z6-0 start"><li class="c18 c37 li-bullet-0"><span class="c6">Develop a parallel implementation of the sorting kernel</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-1 start"><li class="c18 c24 li-bullet-0"><span class="c6">Since the force kernel has been optimized, this kernel now takes a significant portion of the total runtime</span></li><li class="c18 c24 li-bullet-0"><span class="c6">Then we could examine tradeoffs between the time it takes to sort and the benefit to the force calculations</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-0"><li class="c18 c37 li-bullet-0"><span class="c6">Improve the force calculation stack to work with a larger block size</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-1 start"><li class="c18 c24 li-bullet-0"><span class="c6">This would improve SM occupancy</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-0"><li class="c18 c37 li-bullet-0"><span class="c6">Explore dynamic scheduling for the force calculation kernel</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-1 start"><li class="c18 c24 li-bullet-0"><span class="c6">This would significantly help workload imbalance</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-0"><li class="c18 c37 li-bullet-0"><span class="c6">Explore different sorts for the sorting kernel</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-1 start"><li class="c18 c24 li-bullet-0"><span class="c6">We currently use inorder, but perhaps there are other sorts that would be better</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-0"><li class="c18 c37 li-bullet-0"><span class="c6">Explore our code&rsquo;s performance on non-GHC GPUs</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-1 start"><li class="c18 c24 li-bullet-0"><span class="c6">We could attempt larger problem sizes on GPUs with more memory or see how our code performs on less-powerful GPUs</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-0"><li class="c18 c37 li-bullet-0"><span class="c6">Explore sorting the mass and position arrays</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-1 start"><li class="c18 c24 li-bullet-0"><span class="c6">Could spending more time in the sort kernel lead be a tradeoff for spending less time in the force calculation kernel?</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-0"><li class="c18 c37 li-bullet-0"><span class="c6">Investigate how the uniformity of distribution of stars impacts performance</span></li></ul><ul class="c1 lst-kix_49l6hhcwk3z6-1 start"><li class="c18 c24 li-bullet-0"><span class="c6">Configurations where there are lots of tight clumps of stars spread out over large distances would result in a quadtree with many layers and a lot of empty nodes. This is not ideal, so how detrimental is this to performance?</span></li><li class="c18 c24 li-bullet-0"><span>Similarly, configurations where stars are evenly spaced out results in a more compact tree.</span><hr style="page-break-before:always;display:none;"></li></ul><h1 class="c58" id="h.18fpfamrn9r9"><span class="c48">References</span></h1><p class="c10"><span>Jianqiao Liu, Michael Robson, Thomas Quinn, and Milind Kulkarni. 2019. Efficient GPU tree walks for effective distributed n-body simulations. In Proceedings of the ACM International Conference on Supercomputing (ICS &#39;19). Association for Computing Machinery, New York, NY, USA, 24&ndash;34. </span><span class="c34"><a class="c26" href="https://www.google.com/url?q=https://doi.org/10.1145/3330345.3330348&amp;sa=D&amp;source=editors&amp;ust=1745923136333484&amp;usg=AOvVaw0D_xtAaD-fIZn2hmANBMh7">https://doi.org/10.1145/3330345.3330348</a></span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">M. Burtscher and K. Pingali. &quot;An Efficient CUDA Implementation of the Tree-based Barnes Hut n-Body Algorithm&quot;. Chapter 6 in GPU Computing Gems Emerald Edition, pp. 75-92. January 2011.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c34"><a class="c26" href="https://www.google.com/url?q=https://userweb.cs.txstate.edu/~mb92/research/ECL-BH/&amp;sa=D&amp;source=editors&amp;ust=1745923136335063&amp;usg=AOvVaw0nJbhovISQop4xvYtCO0TN">https://userweb.cs.txstate.edu/~mb92/research/ECL-BH/</a></span><span class="c6">&nbsp;- Barnes-Hut CUDA code</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c34"><a class="c26" href="https://www.google.com/url?q=https://arborjs.org/docs/barnes-hut&amp;sa=D&amp;source=editors&amp;ust=1745923136335664&amp;usg=AOvVaw2z5rnsDbN-EMa93SvLQs9w">https://arborjs.org/docs/barnes-hut</a></span><span class="c6">&nbsp;- diagrams and understanding of the Barnes-Hut algorithm</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c34"><a class="c26" href="https://www.google.com/url?q=https://beltoforion.de/en/barnes-hut-galaxy-simulator/&amp;sa=D&amp;source=editors&amp;ust=1745923136336481&amp;usg=AOvVaw0itvDqy32SVxpgD2f7E7Sb">https://beltoforion.de/en/barnes-hut-galaxy-simulator/</a></span><span class="c6">&nbsp;- more Barnes-Hut descriptions and pseudocode</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10 c11"><span class="c6"></span></p><hr><p class="c10 c11"><span class="c6"></span></p><p class="c10 c11"><span class="c6"></span></p><p class="c42 title" id="h.ub7vxzzwao9"><span class="c92">Initial Proposal</span></p><h1 class="c35" id="h.ypt16wicg1eq"><span class="c48">Barnes-Hut Tree Walking Strategies in CUDA</span></h1><h2 class="c65" id="h.6fei469ifgss"><span class="c25">Website URL</span></h2><p class="c10"><span class="c34"><a class="c26" href="https://www.google.com/url?q=https://jrohozen.github.io/418-website/&amp;sa=D&amp;source=editors&amp;ust=1745923136338125&amp;usg=AOvVaw0sThIdNdW2l7DHZvmyozCl">https://jrohozen.github.io/418-website/</a></span></p><h2 class="c65" id="h.d6omlorzle8t"><span class="c25">Summary</span></h2><ul class="c1 lst-kix_2jj8uwmiysve-0 start"><li class="c10 c37 li-bullet-0"><span class="c6">We are going to implement two different tree-walking strategies for Barnes-Hut using CUDA.</span></li><li class="c10 c37 li-bullet-0"><span class="c6">We will optimize these strategies for the GHC GPUs and compare their results and speedups versus a serial CPU implementation of the Barnes-Hut algorithm on the GHC machines.</span></li><li class="c10 c37 li-bullet-0"><span class="c6">In particular, we will compare the performance of a dual-tree to a single-tree on a GPU.</span></li></ul><h2 class="c65" id="h.ify2dalo1rj7"><span class="c25">Background</span></h2><p class="c10"><span>The Barnes-Hut algorithm is an O(</span><span>nlogn</span><span class="c6">) algorithm to simulate galaxy evolution. The algorithm is performed over many time steps. Each time step is done serially, but we will parallelize within time steps. The main data structure for this algorithm is the quadtree. The quadtree divides stars up based on their location. Each leaf node corresponds to exactly one star. The interior nodes of the tree hold the aggregate mass and center of mass for its children nodes.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">On each time step, the original Barnes-Hut algorithm builds the quadtree and then fills in aggregate mass and center of mass for each interior node. As a modification, our algorithm will also build an interaction list before iterating over particles. The interaction list will be used to calculate the forces on particles efficiently on a GPU. </span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">The pseudocode for the algorithm we will use follows. This is the pseudocode given in lecture with the modification of the lines in red.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c4">for each time step in simulation:</span></p><p class="c10"><span class="c4">&nbsp; build tree structure</span></p><p class="c10"><span class="c4">&nbsp; compute (aggregate mass, center-of-mass) for interior nodes</span></p><p class="c10"><span class="c103">&nbsp; </span><span class="c89">traverse tree to assemble interactions list</span></p><p class="c10"><span class="c4">&nbsp; for each particle:</span></p><p class="c10"><span class="c53">&nbsp; &nbsp; </span><span class="c89">use interactions list</span><span class="c4">&nbsp;to accumulate gravitational forces</span></p><p class="c10"><span class="c53">&nbsp; &nbsp; update particle position based on gravitational forces</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">The portion of the algorithm that is of primary interest is the method of traversing the quadtree to compose interaction lists for each star in a way that performs well on a GPU.</span></p><h2 class="c65" id="h.jyhhhrlnomdb"><span class="c25">The Challenge</span></h2><p class="c10"><span class="c6">It is difficult to efficiently traverse the tree in a GPU-friendly way. &nbsp;The part about Barnes-Hut that is GPU-friendly is when calculating the forces on a given star when the inputs to that calculation are already decided. &nbsp;Shared memory, cache locality, and SIMD registers can be leveraged to accelerate this process.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">There will be a high communication to computation ratio especially if you include the time it takes to compose the interactions list. &nbsp;The portion computing the forces on the stars will be relatively quick once an interactions list is composed.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">However, optimizing how to get to that point is the tricky part due to thread divergence when traversing a tree. &nbsp;Recursion and thread divergence are not ideal for a GPU because GPUs rely on doing the same or similar calculations many times. &nbsp;What&rsquo;s interesting is that for these reasons, the dual-tree walk has a better asymptotic complexity than the single-tree approach, however, based on analysis done by Liu et al, the authors found that a single-tree implementation still performed better on a GPU. &nbsp;We want to compare our findings to those in the &ldquo;Efficient GPU Tree Walk&rdquo; paper and evaluate any differences we may find.</span></p><h2 class="c65" id="h.gdho3dwcvc53"><span class="c25">Resources</span></h2><p class="c10"><span>Jianqiao Liu, Michael Robson, Thomas Quinn, and Milind Kulkarni. 2019. Efficient GPU tree walks for effective distributed n-body simulations. In Proceedings of the ACM International Conference on Supercomputing (ICS &#39;19). Association for Computing Machinery, New York, NY, USA, 24&ndash;34. </span><span class="c34"><a class="c26" href="https://www.google.com/url?q=https://doi.org/10.1145/3330345.3330348&amp;sa=D&amp;source=editors&amp;ust=1745923136351149&amp;usg=AOvVaw1tS3nQ35IRXm24jZ1Eq-V8">https://doi.org/10.1145/3330345.3330348</a></span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">M. Burtscher and K. Pingali. &quot;An Efficient CUDA Implementation of the Tree-based Barnes Hut n-Body Algorithm&quot;. Chapter 6 in GPU Computing Gems Emerald Edition, pp. 75-92. January 2011.</span></p><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span>Article about Barnes-Hut: </span><span class="c34"><a class="c26" href="https://www.google.com/url?q=https://arborjs.org/docs/barnes-hut&amp;sa=D&amp;source=editors&amp;ust=1745923136352090&amp;usg=AOvVaw18LLwkAD7xnW9NhZe_EI9P">The Barnes-Hut Algorithm</a></span></p><p class="c10"><span>Another article: </span><span class="c34"><a class="c26" href="https://www.google.com/url?q=https://beltoforion.de/en/barnes-hut-galaxy-simulator/&amp;sa=D&amp;source=editors&amp;ust=1745923136352397&amp;usg=AOvVaw3U38rr-FjadvJNJazcZBsG">The Barnes-Hut Galaxy Simulator</a></span><span>&nbsp;and </span><span class="c34"><a class="c26" href="https://www.google.com/url?q=https://github.com/beltoforion/Barnes-Hut-Simulator/blob/master/README.md&amp;sa=D&amp;source=editors&amp;ust=1745923136352718&amp;usg=AOvVaw3iLazNC5SsKPW_KiQS5DTc">Barnes-Hut-Simulator/README.md at master &middot; beltoforion/Barnes-Hut-Simulator &middot; GitHub</a></span></p><h2 class="c65" id="h.4rue8pwefqqk"><span class="c25">Goals and Deliverables</span></h2><p class="c10"><span class="c6">We plan to achieve the following goals:<br></span></p><ul class="c1 lst-kix_v71v1sb3yh2k-0 start"><li class="c10 c37 li-bullet-0"><span class="c6">Implementation of Barnes-Hut using a dual-tree walking strategy in CUDA.</span></li><li class="c10 c37 li-bullet-0"><span class="c6">Implementation of Barnes-Hut using a single-tree walking strategy in CUDA.</span></li><li class="c10 c37 li-bullet-0"><span class="c6">Cache misses, synchronization stalls, runtime breakdowns, and speedup data for both implementations.</span></li><li class="c10 c37 li-bullet-0"><span class="c6">Program to write random particle inputs and validate the outputs.</span></li></ul><p class="c10 c11"><span class="c6"></span></p><p class="c10"><span class="c6">We hope to achieve the following goals:</span></p><p class="c10 c11"><span class="c6"></span></p><ul class="c1 lst-kix_pnndopbxg7rj-0 start"><li class="c10 c37 li-bullet-0"><span class="c6">Implementation of a dual-tree walk using OpenMP to run on a CPU.</span></li><li class="c10 c37 li-bullet-0"><span class="c6">Program to visualize particle movement/galaxy evolution over time.</span></li></ul><h2 class="c65" id="h.128fjt1wcsfn"><span class="c25">Platform Choice</span></h2><p class="c10"><span class="c6">We will use the GPUs in the GHC machines. We also have other (personal) devices with older GPUs, and we may test our code on these if we have time. We are choosing to use GPUs because we think it is an interesting question to push GPU performance for Barnes-Hut. &nbsp;One the one hand, the force calculation portion of Barnes-Hut is excellent for a GPU because it&rsquo;s a lot of the same calculations run on a large set of data at once. &nbsp;However, the preparation of that data is not easily done on a GPU because it involves tree traversal and thread divergence. &nbsp;We want to see if we can reduce this bottleneck by finding a better way to compose the interactions lists on a GPU, or in parallel on a CPU.</span></p><p class="c10 c11"><span class="c6"></span></p><hr><p class="c10 c11"><span class="c6"></span></p><p class="c10 c11"><span class="c6"></span></p><p class="c42 title" id="h.jhfmfrpklphi"><span class="c92">Milestone Report</span></p><h1 class="c35" id="h.570it9mhvc5n"><span class="c48">Revised Schedule</span></h1><p class="c10 c11"><span class="c6"></span></p><table class="c61"><tr class="c59"><td class="c93 c69" colspan="1" rowspan="1"><p class="c57"><span class="c33">Date</span></p></td><td class="c44 c69" colspan="1" rowspan="1"><p class="c57"><span class="c33">Goal</span></p></td><td class="c8 c69" colspan="1" rowspan="1"><p class="c57"><span class="c33">Assignee</span></p></td></tr><tr class="c59"><td class="c93" colspan="1" rowspan="1"><p class="c57"><span class="c6">Thursday, April 10, 11:59pm</span></p></td><td class="c44" colspan="1" rowspan="1"><ul class="c1 lst-kix_3urcczrnk5zr-0 start"><li class="c21 li-bullet-0"><span class="c120 c113 c110">Serial implementation on CPU</span></li><li class="c21 li-bullet-0"><span class="c113 c110 c120">Program for generating inputs and validating implementations</span></li><li class="c21 li-bullet-0"><span class="c6">Worked on serial implementation input generation</span></li></ul></td><td class="c8" colspan="1" rowspan="1"><p class="c41"><span class="c6">Delaynie + Jacob</span></p></td></tr><tr class="c59"><td class="c93" colspan="1" rowspan="1"><p class="c57"><span class="c6">Friday, April 18, 11:59pm</span></p></td><td class="c44" colspan="1" rowspan="1"><ul class="c1 lst-kix_bdvlsg70sq8v-0 start"><li class="c21 li-bullet-0"><span class="c6">Done: serial implementation, input generation, and visualization</span></li><li class="c21 li-bullet-0"><span class="c6">Finish single-tree CUDA implementation.</span></li><li class="c21 li-bullet-0"><span class="c6">Make progress on dual-tree CUDA implementation.</span></li></ul></td><td class="c8" colspan="1" rowspan="1"><p class="c41"><span class="c6">Delaynie + Jacob</span></p></td></tr><tr class="c59"><td class="c93" colspan="1" rowspan="1"><p class="c57"><span class="c6">Tuesday, April 22, 11:59pm</span></p></td><td class="c44" colspan="1" rowspan="1"><ul class="c1 lst-kix_9mugulzewaai-0 start"><li class="c21 li-bullet-0"><span class="c6">Collect and analyze data for single-tree CUDA implementation.</span></li><li class="c21 li-bullet-0"><span class="c6">Start outlining final report.</span></li><li class="c21 li-bullet-0"><span class="c6">Optimize single-tree CUDA implementation.</span></li><li class="c21 li-bullet-0"><span class="c6">Continue working on dual-tree CUDA implementation.</span></li></ul></td><td class="c8" colspan="1" rowspan="1"><p class="c41"><span class="c6">Delaynie + Jacob</span></p></td></tr><tr class="c59"><td class="c93" colspan="1" rowspan="1"><p class="c57"><span class="c6">Friday, April 25, 11:59pm</span></p></td><td class="c44" colspan="1" rowspan="1"><ul class="c1 lst-kix_ri3rwq8w4csm-0 start"><li class="c21 li-bullet-0"><span class="c6">Finish dual-tree CUDA implementation.</span></li><li class="c21 li-bullet-0"><span class="c6">Collect and analyze data.</span></li><li class="c21 li-bullet-0"><span class="c6">Keep working on final report.</span></li></ul></td><td class="c8" colspan="1" rowspan="1"><p class="c41"><span class="c6">Delaynie + Jacob</span></p></td></tr><tr class="c59"><td class="c93" colspan="1" rowspan="1"><p class="c57"><span class="c6 c16">Monday April 28th, 11:59pm</span></p></td><td class="c44" colspan="1" rowspan="1"><ul class="c1 lst-kix_q1k1i97sl5wh-0 start"><li class="c21 li-bullet-0"><span class="c6">Generate, visualize, and analyze data</span></li><li class="c21 li-bullet-0"><span class="c33">Final Report Due</span></li></ul></td><td class="c8" colspan="1" rowspan="1"><p class="c41"><span class="c6">Delaynie + Jacob</span></p></td></tr><tr class="c59"><td class="c93" colspan="1" rowspan="1"><p class="c57"><span class="c6 c16">April 29th, 5:30-8:30pm</span></p></td><td class="c44" colspan="1" rowspan="1"><ul class="c1 lst-kix_mq787rs9iun6-0 start"><li class="c21 li-bullet-0"><span class="c33">Poster Session</span></li></ul></td><td class="c8" colspan="1" rowspan="1"><p class="c41"><span class="c6">Delaynie + Jacob</span></p></td></tr></table><p class="c10 c11"><span class="c6"></span></p><h1 class="c35" id="h.ugwnj0tyhogw"><span class="c48">Current Progress</span></h1><p class="c10"><span class="c6">So far, we have a serial implementation of Barnes-Hut and a program for generating inputs for validating our parallel implementations. &nbsp;Additionally, we have a Python program to visualize the simulation over time. We have spent a lot of time reading through several papers and websites, particularly focusing on how to implement tree-building and tree walks in parallel. &nbsp;We&rsquo;ve brainstormed a data structure based off of Burtscher and Pingali&rsquo;s paper that represents a quadtree as a set of arrays stored in shared memory.</span></p><h1 class="c35" id="h.88fdl97z28u"><span class="c48">Goals and Deliverables</span></h1><p class="c10"><span class="c6">Based off of our original proposal, we are a bit behind regarding code deliverables. &nbsp;Because of the last exam and Carnival, we didn&rsquo;t spend enough time initially as we needed to on doing background research so that we would be prepared to write implementations of Barnes-Hut. &nbsp;We still plan to deliver both single-tree and dual-tree CUDA implementations of Barnes-Hut, along with runtime breakdowns, synchronization stalls, and speedup data comparing the two.</span></p><h1 class="c35" id="h.61gfy74vdip5"><span class="c48">Poster Session</span></h1><p class="c10"><span class="c6">Our poster will mainly consist of graphs of the data we collected comparing the Barnes-Hut implementations. We also plan to include some images from our simulation visualizer.</span></p><h1 class="c35" id="h.pnxjeqlc7glm"><span class="c48">Concerns</span></h1><p class="c10"><span class="c6">Our main concern is our ability to write both implementations in time. &nbsp;Since we&rsquo;re synthesizing ideas inspired by several different sources, our interfaces and data structures need to be carefully thought out so that they&rsquo;re both compatible and efficient across sections of our code.</span></p></body></html>