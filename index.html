<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=lhDjYqiy3mZ0x6ROQEUoUw);.lst-kix_df0sawy36zlq-4>li:before{content:"\0025cb   "}.lst-kix_df0sawy36zlq-1>li:before{content:"\0025cb   "}.lst-kix_df0sawy36zlq-5>li:before{content:"\0025a0   "}ul.lst-kix_2fsxrvln3azi-7{list-style-type:none}.lst-kix_df0sawy36zlq-0>li:before{content:"\0025cf   "}.lst-kix_df0sawy36zlq-8>li:before{content:"\0025a0   "}ul.lst-kix_2fsxrvln3azi-8{list-style-type:none}ul.lst-kix_2fsxrvln3azi-5{list-style-type:none}ul.lst-kix_2fsxrvln3azi-6{list-style-type:none}.lst-kix_df0sawy36zlq-6>li:before{content:"\0025cf   "}.lst-kix_df0sawy36zlq-7>li:before{content:"\0025cb   "}.lst-kix_2fsxrvln3azi-1>li:before{content:"\0025cb   "}.lst-kix_ggxpggkp3oj0-4>li:before{content:"\0025cb   "}.lst-kix_ggxpggkp3oj0-6>li:before{content:"\0025cf   "}.lst-kix_miw7ums72yq6-6>li:before{content:"\0025cf   "}.lst-kix_miw7ums72yq6-8>li:before{content:"\0025a0   "}.lst-kix_64t38yuzg7ae-1>li:before{content:"\0025cb   "}.lst-kix_2fsxrvln3azi-0>li:before{content:"\0025cf   "}.lst-kix_ggxpggkp3oj0-5>li:before{content:"\0025a0   "}.lst-kix_miw7ums72yq6-3>li:before{content:"\0025cf   "}.lst-kix_miw7ums72yq6-7>li:before{content:"\0025cb   "}.lst-kix_64t38yuzg7ae-2>li:before{content:"\0025a0   "}.lst-kix_ggxpggkp3oj0-8>li:before{content:"\0025a0   "}.lst-kix_miw7ums72yq6-4>li:before{content:"\0025cb   "}.lst-kix_df0sawy36zlq-2>li:before{content:"\0025a0   "}.lst-kix_df0sawy36zlq-3>li:before{content:"\0025cf   "}.lst-kix_azxbdc2b1sav-6>li:before{content:"\0025cf   "}.lst-kix_ggxpggkp3oj0-7>li:before{content:"\0025cb   "}.lst-kix_miw7ums72yq6-5>li:before{content:"\0025a0   "}.lst-kix_64t38yuzg7ae-0>li:before{content:"\0025cf   "}.lst-kix_2fsxrvln3azi-7>li:before{content:"\0025cb   "}.lst-kix_azxbdc2b1sav-7>li:before{content:"\0025cb   "}.lst-kix_2fsxrvln3azi-8>li:before{content:"\0025a0   "}.lst-kix_azxbdc2b1sav-8>li:before{content:"\0025a0   "}.lst-kix_ggxpggkp3oj0-1>li:before{content:"\0025cb   "}.lst-kix_2fsxrvln3azi-3>li:before{content:"\0025cf   "}.lst-kix_ggxpggkp3oj0-2>li:before{content:"\0025a0   "}.lst-kix_2fsxrvln3azi-2>li:before{content:"\0025a0   "}.lst-kix_ggxpggkp3oj0-3>li:before{content:"\0025cf   "}.lst-kix_k8covgqtsad4-4>li:before{content:"\0025cb   "}.lst-kix_k8covgqtsad4-3>li:before{content:"\0025cf   "}.lst-kix_2fsxrvln3azi-4>li:before{content:"\0025cb   "}.lst-kix_k8covgqtsad4-2>li:before{content:"\0025a0   "}.lst-kix_2fsxrvln3azi-5>li:before{content:"\0025a0   "}.lst-kix_ggxpggkp3oj0-0>li:before{content:"\0025cf   "}.lst-kix_k8covgqtsad4-1>li:before{content:"\0025cb   "}.lst-kix_2fsxrvln3azi-6>li:before{content:"\0025cf   "}.lst-kix_k8covgqtsad4-0>li:before{content:"\0025cf   "}.lst-kix_k8covgqtsad4-5>li:before{content:"\0025a0   "}ul.lst-kix_ggxpggkp3oj0-0{list-style-type:none}ul.lst-kix_ggxpggkp3oj0-1{list-style-type:none}.lst-kix_k8covgqtsad4-6>li:before{content:"\0025cf   "}.lst-kix_k8covgqtsad4-7>li:before{content:"\0025cb   "}.lst-kix_k8covgqtsad4-8>li:before{content:"\0025a0   "}ul.lst-kix_miw7ums72yq6-1{list-style-type:none}ul.lst-kix_azxbdc2b1sav-8{list-style-type:none}ul.lst-kix_miw7ums72yq6-2{list-style-type:none}ul.lst-kix_miw7ums72yq6-3{list-style-type:none}.lst-kix_azxbdc2b1sav-5>li:before{content:"\0025a0   "}ul.lst-kix_miw7ums72yq6-4{list-style-type:none}.lst-kix_64t38yuzg7ae-7>li:before{content:"\0025cb   "}.lst-kix_azxbdc2b1sav-4>li:before{content:"\0025cb   "}ul.lst-kix_miw7ums72yq6-0{list-style-type:none}.lst-kix_64t38yuzg7ae-6>li:before{content:"\0025cf   "}ul.lst-kix_ggxpggkp3oj0-2{list-style-type:none}ul.lst-kix_ggxpggkp3oj0-3{list-style-type:none}ul.lst-kix_ggxpggkp3oj0-4{list-style-type:none}.lst-kix_azxbdc2b1sav-1>li:before{content:"\0025cb   "}.lst-kix_azxbdc2b1sav-3>li:before{content:"\0025cf   "}ul.lst-kix_ggxpggkp3oj0-5{list-style-type:none}.lst-kix_64t38yuzg7ae-3>li:before{content:"\0025cf   "}.lst-kix_64t38yuzg7ae-5>li:before{content:"\0025a0   "}ul.lst-kix_ggxpggkp3oj0-6{list-style-type:none}ul.lst-kix_miw7ums72yq6-5{list-style-type:none}ul.lst-kix_ggxpggkp3oj0-7{list-style-type:none}ul.lst-kix_miw7ums72yq6-6{list-style-type:none}ul.lst-kix_ggxpggkp3oj0-8{list-style-type:none}ul.lst-kix_miw7ums72yq6-7{list-style-type:none}.lst-kix_azxbdc2b1sav-2>li:before{content:"\0025a0   "}ul.lst-kix_miw7ums72yq6-8{list-style-type:none}.lst-kix_64t38yuzg7ae-4>li:before{content:"\0025cb   "}ul.lst-kix_2fsxrvln3azi-0{list-style-type:none}ul.lst-kix_2fsxrvln3azi-3{list-style-type:none}ul.lst-kix_2fsxrvln3azi-4{list-style-type:none}ul.lst-kix_2fsxrvln3azi-1{list-style-type:none}ul.lst-kix_2fsxrvln3azi-2{list-style-type:none}.lst-kix_azxbdc2b1sav-0>li:before{content:"\0025cf   "}ul.lst-kix_azxbdc2b1sav-1{list-style-type:none}ul.lst-kix_azxbdc2b1sav-0{list-style-type:none}ul.lst-kix_azxbdc2b1sav-3{list-style-type:none}ul.lst-kix_azxbdc2b1sav-2{list-style-type:none}ul.lst-kix_azxbdc2b1sav-5{list-style-type:none}ul.lst-kix_azxbdc2b1sav-4{list-style-type:none}ul.lst-kix_azxbdc2b1sav-7{list-style-type:none}ul.lst-kix_azxbdc2b1sav-6{list-style-type:none}.lst-kix_64t38yuzg7ae-8>li:before{content:"\0025a0   "}.lst-kix_29o1m6h8nwpq-4>li:before{content:"\0025cb   "}.lst-kix_29o1m6h8nwpq-5>li:before{content:"\0025a0   "}.lst-kix_29o1m6h8nwpq-6>li:before{content:"\0025cf   "}.lst-kix_29o1m6h8nwpq-7>li:before{content:"\0025cb   "}.lst-kix_29o1m6h8nwpq-8>li:before{content:"\0025a0   "}ul.lst-kix_df0sawy36zlq-5{list-style-type:none}ul.lst-kix_df0sawy36zlq-6{list-style-type:none}ul.lst-kix_df0sawy36zlq-3{list-style-type:none}ul.lst-kix_df0sawy36zlq-4{list-style-type:none}ul.lst-kix_k8covgqtsad4-8{list-style-type:none}ul.lst-kix_df0sawy36zlq-7{list-style-type:none}ul.lst-kix_k8covgqtsad4-6{list-style-type:none}ul.lst-kix_df0sawy36zlq-8{list-style-type:none}ul.lst-kix_k8covgqtsad4-7{list-style-type:none}.lst-kix_29o1m6h8nwpq-3>li:before{content:"\0025cf   "}.lst-kix_29o1m6h8nwpq-1>li:before{content:"\0025cb   "}.lst-kix_29o1m6h8nwpq-2>li:before{content:"\0025a0   "}.lst-kix_7ktpo1wo4r5c-2>li:before{content:"-  "}ul.lst-kix_k8covgqtsad4-4{list-style-type:none}ul.lst-kix_k8covgqtsad4-5{list-style-type:none}.lst-kix_29o1m6h8nwpq-0>li:before{content:"\0025cf   "}ul.lst-kix_k8covgqtsad4-2{list-style-type:none}ul.lst-kix_k8covgqtsad4-3{list-style-type:none}.lst-kix_7ktpo1wo4r5c-1>li:before{content:"-  "}ul.lst-kix_k8covgqtsad4-0{list-style-type:none}ul.lst-kix_k8covgqtsad4-1{list-style-type:none}.lst-kix_7ktpo1wo4r5c-0>li:before{content:"-  "}.lst-kix_7ktpo1wo4r5c-7>li:before{content:"-  "}ul.lst-kix_29o1m6h8nwpq-2{list-style-type:none}.lst-kix_viptijntu88s-7>li:before{content:"-  "}.lst-kix_viptijntu88s-8>li:before{content:"-  "}ul.lst-kix_29o1m6h8nwpq-1{list-style-type:none}ul.lst-kix_29o1m6h8nwpq-4{list-style-type:none}ul.lst-kix_29o1m6h8nwpq-3{list-style-type:none}.lst-kix_7ktpo1wo4r5c-6>li:before{content:"-  "}ul.lst-kix_29o1m6h8nwpq-0{list-style-type:none}.lst-kix_7ktpo1wo4r5c-3>li:before{content:"-  "}.lst-kix_viptijntu88s-3>li:before{content:"-  "}.lst-kix_7ktpo1wo4r5c-5>li:before{content:"-  "}.lst-kix_viptijntu88s-1>li:before{content:"-  "}.lst-kix_viptijntu88s-2>li:before{content:"-  "}.lst-kix_7ktpo1wo4r5c-4>li:before{content:"-  "}ul.lst-kix_viptijntu88s-8{list-style-type:none}ul.lst-kix_viptijntu88s-7{list-style-type:none}ul.lst-kix_viptijntu88s-6{list-style-type:none}ul.lst-kix_viptijntu88s-5{list-style-type:none}.lst-kix_viptijntu88s-4>li:before{content:"-  "}ul.lst-kix_df0sawy36zlq-1{list-style-type:none}ul.lst-kix_29o1m6h8nwpq-6{list-style-type:none}ul.lst-kix_df0sawy36zlq-2{list-style-type:none}.lst-kix_viptijntu88s-5>li:before{content:"-  "}.lst-kix_viptijntu88s-6>li:before{content:"-  "}ul.lst-kix_29o1m6h8nwpq-5{list-style-type:none}.lst-kix_7ktpo1wo4r5c-8>li:before{content:"-  "}ul.lst-kix_29o1m6h8nwpq-8{list-style-type:none}ul.lst-kix_df0sawy36zlq-0{list-style-type:none}ul.lst-kix_29o1m6h8nwpq-7{list-style-type:none}ul.lst-kix_64t38yuzg7ae-1{list-style-type:none}ul.lst-kix_64t38yuzg7ae-0{list-style-type:none}.lst-kix_miw7ums72yq6-0>li:before{content:"\0025cf   "}ul.lst-kix_viptijntu88s-0{list-style-type:none}ul.lst-kix_64t38yuzg7ae-8{list-style-type:none}ul.lst-kix_64t38yuzg7ae-7{list-style-type:none}.lst-kix_miw7ums72yq6-2>li:before{content:"\0025a0   "}ul.lst-kix_64t38yuzg7ae-6{list-style-type:none}ul.lst-kix_viptijntu88s-4{list-style-type:none}ul.lst-kix_64t38yuzg7ae-5{list-style-type:none}ul.lst-kix_viptijntu88s-3{list-style-type:none}ul.lst-kix_64t38yuzg7ae-4{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ul.lst-kix_viptijntu88s-2{list-style-type:none}ul.lst-kix_64t38yuzg7ae-3{list-style-type:none}ul.lst-kix_viptijntu88s-1{list-style-type:none}.lst-kix_miw7ums72yq6-1>li:before{content:"\0025cb   "}ul.lst-kix_64t38yuzg7ae-2{list-style-type:none}ul.lst-kix_7ktpo1wo4r5c-0{list-style-type:none}.lst-kix_viptijntu88s-0>li:before{content:"-  "}ul.lst-kix_7ktpo1wo4r5c-1{list-style-type:none}ul.lst-kix_7ktpo1wo4r5c-2{list-style-type:none}ul.lst-kix_7ktpo1wo4r5c-7{list-style-type:none}ul.lst-kix_7ktpo1wo4r5c-8{list-style-type:none}ul.lst-kix_7ktpo1wo4r5c-3{list-style-type:none}ul.lst-kix_7ktpo1wo4r5c-4{list-style-type:none}ul.lst-kix_7ktpo1wo4r5c-5{list-style-type:none}ul.lst-kix_7ktpo1wo4r5c-6{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c27{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c20{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:79.5pt;border-top-color:#000000;border-bottom-style:solid}.c35{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:79.5pt;border-top-color:#cccccc;border-bottom-style:solid}.c80{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:79.5pt;border-top-color:#cccccc;border-bottom-style:solid}.c101{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#000000;border-bottom-style:solid}.c43{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c4{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c48{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#cccccc;border-bottom-style:solid}.c109{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c97{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#000000;border-bottom-style:solid}.c34{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c116{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:150pt;border-top-color:#000000;border-bottom-style:solid}.c57{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c115{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c91{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c67{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c94{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c51{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#cccccc;border-bottom-style:solid}.c42{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#cccccc;border-bottom-style:solid}.c103{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c90{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#000000;border-bottom-style:solid}.c58{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:472.5pt;border-top-color:#000000;border-bottom-style:solid}.c25{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c60{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c63{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#cccccc;border-bottom-style:solid}.c112{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:150pt;border-top-color:#000000;border-bottom-style:solid}.c32{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c105{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c86{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#000000;border-bottom-style:solid}.c87{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c75{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#cccccc;border-bottom-style:solid}.c73{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:79.5pt;border-top-color:#cccccc;border-bottom-style:solid}.c74{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c69{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c93{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c78{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#000000;border-bottom-style:solid}.c26{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c98{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#000000;border-bottom-style:solid}.c82{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c24{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:477pt;border-top-color:#000000;border-bottom-style:solid}.c5{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#000000;border-bottom-style:solid}.c85{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c62{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#000000;border-bottom-style:solid}.c70{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c59{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#cccccc;border-bottom-style:solid}.c17{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#cccccc;border-bottom-style:solid}.c65{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c95{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c55{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c113{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#000000;border-bottom-style:solid}.c46{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c18{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#e0f7fa;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c53{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c84{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#fef8e3;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c28{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#cccccc;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#cccccc;border-bottom-style:solid}.c99{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#ffffff;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#cccccc;border-bottom-style:solid}.c81{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;background-color:#f7cb4d;border-left-style:solid;border-bottom-width:1pt;width:79.5pt;border-top-color:#cccccc;border-bottom-style:solid}.c49{border-right-style:solid;padding:2pt 2pt 2pt 2pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:bottom;border-right-color:#cccccc;border-left-width:1pt;border-top-style:solid;background-color:#4dd0e1;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#cccccc;border-bottom-style:solid}.c15{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:75pt;border-top-color:#000000;border-bottom-style:solid}.c44{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:125.2pt;border-top-color:#000000;border-bottom-style:solid}.c39{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:119.2pt;border-top-color:#000000;border-bottom-style:solid}.c31{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:234pt;border-top-color:#000000;border-bottom-style:solid}.c92{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:123pt;border-top-color:#000000;border-bottom-style:solid}.c89{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#cccccc;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:144.8pt;border-top-color:#000000;border-bottom-style:solid}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c2{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Consolas";font-style:normal}.c77{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c108{background-color:#ffff00;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Comic Sans MS";font-style:normal}.c79{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c41{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:26pt;font-family:"Arial";font-style:normal}.c66{padding-top:20pt;padding-bottom:6pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c71{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Arial";font-style:normal}.c22{color:#434343;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c61{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c23{padding-top:16pt;padding-bottom:4pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c38{padding-top:18pt;padding-bottom:6pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c96{padding-top:0pt;padding-bottom:3pt;line-height:1.5;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c16{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c88{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c6{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c102{padding-top:0pt;padding-bottom:4pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c107{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:center}.c37{color:#b7b7b7;text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.c83{color:#999999;text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.c45{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c40{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c104{text-decoration:none;vertical-align:baseline;font-size:11pt;font-style:normal}.c100{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:center}.c14{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:right}.c50{border-spacing:0;border-collapse:collapse;margin-right:auto}.c21{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:right}.c12{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c8{padding-top:0pt;padding-bottom:0pt;line-height:1.5;text-align:left}.c29{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c64{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c106{font-weight:400;font-family:"Arial"}.c72{color:inherit;text-decoration:inherit}.c30{padding:0;margin:0}.c36{margin-left:36pt;padding-left:0pt}.c11{margin-left:72pt;padding-left:0pt}.c111{background-color:#ffff00;color:#ff00ff}.c9{font-weight:400;font-family:"Consolas"}.c68{margin-left:4.5pt;margin-right:-6.8pt}.c19{font-size:10pt;font-weight:700}.c33{height:16pt}.c76{vertical-align:super}.c7{height:11pt}.c114{color:#b7b7b7}.c56{color:#0000ff}.c110{color:#38761d}.c10{height:15.8pt}.c54{color:#ff0000}.c52{font-style:italic}.c47{height:0pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c64 doc-content"><p class="c96 title" id="h.szbp5xgno7xj"><span class="c13">Efficient Force Calculation for Galaxy Simulation in CUDA</span></p><p class="c1"><span class="c79">Delaynie McMillan</span></p><p class="c1"><span class="c79">Jacob Rohozen</span></p><p class="c1"><span class="c79">Tuesday, April 29, 2025</span></p><p class="c16"><span>Website URL: </span><span class="c45"><a class="c72" href="https://www.google.com/url?q=https://jrohozen.github.io/418-website/&amp;sa=D&amp;source=editors&amp;ust=1745921182405464&amp;usg=AOvVaw1qGZ1vqmMp1Ks9Fh48RnJE">https://jrohozen.github.io/418-website/</a></span></p><h1 class="c66" id="h.fgx9lh374m1b"><span>Summary</span></h1><p class="c1"><span>For this project, we set out to implement the Barnes-Hut galaxy simulation algorithm in CUDA. </span><span>Project deliverables</span><span class="c3">&nbsp;include a highly optimized force calculation kernel written in CUDA. We wrote a serial implementation of the algorithm, and measured and compared the performance of our different force calculation kernels. Additionally, we investigate the impact that changing the number of stars and the theta parameter has on runtime and speedup. Analysis of the serial implementation runtime showed that force calculation took up over 95% of the total runtime. Therefore, the main focus of the project was to see how we could optimize the force calculation kernel, in particular.</span></p><h1 class="c66" id="h.e4baexgky4mv"><span class="c71">Background</span></h1><p class="c1"><span>The Barnes-Hut algorithm is an O(</span><span>nlogn</span><span class="c3">) algorithm to simulate star interaction and galaxy evolution over time. The algorithm is performed over many time steps. Time steps must be done in order, but an individual time step can be parallelized.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">The algorithm takes in arrays of data that represent all the stars in the system. Specifically, these arrays characterize the mass, initial position, and initial velocity of each star in the system. We implemented the algorithm in 2D, so the position and velocity arrays contain 2D values.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span>On each time step, the net force on each star is computed and this force results in a change in position and velocity over time. In a naive implementation, the force calculations would be O(n</span><span class="c76">2</span><span class="c3">), with n being the number of stars since each star interacts with every other star (n * (n-1)). The Barnes-Hut algorithm uses an approximation to reduce the amount of force calculations, and the algorithm becomes O(nlogn).</span></p><h2 class="c38" id="h.1m5pu8oeohnq"><span class="c61">The Quadtree</span></h2><p class="c1"><span>The quadtree is the main data structure for Barnes-Hut. The quadtree divides stars up based on their locations in 2D space. The root of the quadtree represents the entire system and is the bounding box for the current step in the simulation. The quadtree is built by recursively subdividing quadrants of the bounding box until every quadrant contains no more than one star. The following diagram shows a set of stars on the left and the resulting quadtree on the right.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 621.15px; height: 269.69px;"><img alt="" src="images/image13.png" style="width: 621.15px; height: 269.69px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">The gray nodes (we will call them quads) have four pointers which can either point to another quad, a star, or nothing (empty). Each quad has a center of mass and a total mass. This information represents the aggregation of all stars within the bounds of that quad.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">The operations performed on a quadtree include traversing the tree, adding a quad, and adding a star. Once the tree is fully constructed, force calculations can be performed. The benefit of the quadtree is that it allows for approximations. Instead of calculating the force on a single star from every other star, Barnes-Hut calculates the force on a single star from other quads if they are sufficiently far away.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span>To add a star to the tree, the star &ldquo;starts&rdquo; at the tree&rsquo;s root. First, the algorithm determines which of the four quads at the root level the star belongs to. This is determined using the star&rsquo;s location and the center of the root quad. If there&rsquo;s already a star in that quad, the quad is further subdivided into four subquads, and the process repeats until the quad is small enough, and this star is the only star in its quad. Similarly, if it is determined that a star belongs in a certain quad, and that quad is already subdivided into smaller quads, we &ldquo;follow&rdquo; that quad until we arrive at an &ldquo;empty&rdquo; quad with no star. </span><span class="c3">Below are illustrations of adding a star to an empty quad, and sub-dividing a quad before inserting a star.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c107"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 551.50px; height: 304.62px;"><img alt="" src="images/image5.png" style="width: 551.50px; height: 304.62px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c107"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 550.00px; height: 310.31px;"><img alt="" src="images/image9.png" style="width: 550.00px; height: 310.31px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c38" id="h.rho61gelautp"><span>Force Calculations</span></h2><p class="c1"><span class="c3">Even though the Barnes-Hut approximation reduces the algorithmic complexity to O(nlogn), the force calculations part of the algorithm still takes more than 95% of the total runtime for a serial implementation. This is why we decided to optimize the force calculations.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">At first glance, there is plenty of work that can be done in parallel. The net force on each star can be independently calculated, and the quadtree is not modified (only read) in this step. This means that no synchronization or atomics are needed for correctness. The same arithmetic steps are being done on large quantities of stars to calculate the net forces on them, which would be a great use of SIMD parallelism. This sounds good, but the Barnes-Hut algorithm maps poorly to GPU execution.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">One problem is that force calculation has low arithmetic intensity. Another problem is that traversing the tree is highly irregular, and this leads to poor locality. Traversing a tree requires accessing a lot of different portions of the quadtree data structure, which results in poor cache locality, especially when one block has threads whose working sets of data do not overlap much. When implemented naively, these problems lead to the algorithm being bandwidth-limited because of poor data reuse. Because of this, our project involved figuring out ways to take advantage of shared memory between threads to reduce memory bandwidth requirements.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">Additionally, the irregular nature of the tree causes another problem: thread divergence. In CUDA, all 32 threads in a warp execute in lockstep. When a warp is traversing a tree some threads will finish before others. Even if only one thread is still traversing the tree, all the other threads will sit idle and wait. Thread divergence reduces the efficiency of the GPU, leading to lower overall throughput.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">Furthermore, the recursive nature of the Barnes-Hut algorithm maps poorly to the CUDA model.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">A later section will discuss our approach to Barnes-Hut and making the force calculations step more amenable to GPU execution.</span></p><h1 class="c66" id="h.v5vxiijkmz61"><span class="c71">Approach</span></h1><p class="c1"><span class="c3">We started by implementing a serial Barnes-Hut algorithm in C++. This served to verify our parallel implementation as we built it up, and we also used the serial code as a benchmark for speedup comparison. The serial implementation had classes and methods for manipulating stars and quads. We did not spend time optimizing the serial version, but we don&rsquo;t feel that it is unreasonably slow (as this would make for an unfair comparison). The serial code was run on the GHC machines.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">We developed a class called Galaxy to randomly generate inputs for both the serial and the CUDA implementations. Galaxies can be made from a customizable size and customizable number of stars orbiting a central supermassive black hole (just another star with a lot more mass). A galaxy can be given an initial position and an initial velocity. This is how we generate multiple galaxies and have them collide. The results of the simulation can be seen using our Python visualizer, and it can output a gif of the simulation also.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">Our parallel implementation is written in CUDA and was also run on the GHC machines, specifically on the NVIDIA GeForce RTX 2080 GPUs. These GPUs have 46 streaming multiprocessors, and this helped inform our kernel launches.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">The first part of making an efficient GPU implementation was changing our data structures.</span></p><h2 class="c38" id="h.34hyp3o6bcar"><span class="c61">Rethinking our Data Structures</span></h2><p class="c1"><span class="c3">In our serial implementation, we used classes for stars and quads and pointers to objects to manipulate class fields. This required dynamically allocating memory for quads and later freeing that memory on every timestep because the quadtree must be rebuilt from updated star positions.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">For our parallel implementation, we chose a more primitive data structure scheme as that gave us more explicit control over data locality. We used arrays, and this approach allowed us to allocate all memory only once for an entire simulation. This saves a lot of time that would otherwise be spent dynamically allocating memory on each timestep.</span></p><h3 class="c23" id="h.xi6ygaruaf4n"><span class="c22">Stars and Individual Quads</span></h3><p class="c1"><span>Drawing inspiration from </span><span>Burtscher and Pingali&rsquo;s paper</span><span class="c3">, we broke our star and quad class properties into separate arrays. For example, instead of using a single array to hold all stars objects, we used one array for each property of the star (mass, position, velocity, force). Additionally, we have a separate array that keeps &nbsp;track of the location of the quads&rsquo; sub-quads. </span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span>For properties that both stars and quads share (i.e. mass and center of mass), we extended the arrays to make space to hold quad properties as well. </span><span class="c3">Since arrays are now shared between stars and quads, we placed star indexes at the front of the array and quad indexes at the end of the array.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 142.67px;"><img alt="" src="images/image14.png" style="width: 624.00px; height: 142.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c23" id="h.f3c3axue1vln"><span>The Quadtree</span></h3><p class="c1"><span class="c3">The data structure for representing the entire quadtree is an array of integers, the quads array. The quads array is basically an array of indexes of quads or stars. Instead of using pointers to objects in memory, we use array indexes that &ldquo;point to&rdquo; other parts of the array. </span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span>We allocate one quad for each star in the system, and each quad requires four integers (its four children). Since some of the arrays (mass and position) contain star and quad values, the quads array grows from the back towards the front as more quads are used. In summary we allocate (quad_limit = 2 </span><img src="images/image1.png"><span>&nbsp;num_stars) quads for the quads array. Then the number of integers allocated is 4 </span><img src="images/image1.png"><span class="c3">&nbsp;quad_limit. The following image shows how our data structures are arranged. </span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 353.33px;"><img alt="" src="images/image6.png" style="width: 624.00px; height: 353.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 337.33px;"><img alt="" src="images/image15.png" style="width: 624.00px; height: 337.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c3">Stars in the simulation will be divided among all the threads launched in the tree build kernel. To be more specific, each thread will be responsible for adding a certain number of stars to the quadtree. Building the quadtree involves adding stars one by one, each time starting at the root of the quadtree (the root&rsquo;s quad index is quad_limit - 1). Adding a star to any quad is similar to the serial implementation with additional steps for handling locks and atomics to ensure correctness. When one thread wants to insert either a star or more quads into an empty quad, atomic CAS is used to ensure that only one thread can successfully modify a single part of the tree at once.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">Locks are necessary when updating the tree requires more than changing (swapping) a single value. This occurs when attempting to add a star to a quadrant already containing a star because this requires shuffling around some values. Before inserting our current star, we must &ldquo;demote&rdquo; the star that&rsquo;s already in the quad, and keep &ldquo;demoting&rdquo; it until the quads are small enough such that both stars are in their own quad. In this case, the thread will attempt to acquire the lock by using atomic CAS to swap the current value (the other star&rsquo;s index) with -2, signifying to other threads that the position is locked. </span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">Since changes only occur at the leaf values of the quadtree (at stars or empty quadrants), we reduced the granularity of our locks to only child values (not entire quads). This allows other threads to make progress if they are not attempting to modify the same position.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span>The states maintained outside of the while loop for inserting a new quad are: the coordinates of the current quad we are trying to insert into</span><span class="c3">, size of said quad, the index of that quad, and the tree depth. State is maintained so that should a CAS for inserting a star or locking a quad fail, the loop restarts and does not have to traverse the entire tree up to that point again. It simply resumes at the index and depth where it left off, once again reading the child value it is attempting to modify, casing on that value, and repeating until success.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span>While developing a scheme for building the quadtree, we drew a lot of inspiration from Burtscher and Pingali&rsquo;s CUDA code for the Barnes-Hut algorithm. This helped us begin reasoning about the benefits and limitations of interacting with a tree using a GPU. </span><span>The pseudocode for inserting stars is below:</span></p><p class="c16 c7"><span class="c2"></span></p><p class="c6"><span class="c9 c37">// assume s1 is the star to be added</span></p><p class="c6"><span class="c2">while (more stars to add) {</span></p><p class="c6"><span class="c2">&nbsp; if (first time attempting to add star to tree) {</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; set current quad to root</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; find which of root&rsquo;s children the star will follow</span></p><p class="c6"><span class="c2">&nbsp; }</span></p><p class="c6"><span class="c2">&nbsp; get child value of current quad</span></p><p class="c6"><span class="c2">&nbsp; while (child is not a quad) {</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; traverse the tree</span></p><p class="c6"><span class="c2">&nbsp; }</span></p><p class="c6"><span class="c9">&nbsp; </span><span class="c9 c114">// child is not a quad: could be a </span><span class="c9 c56">star</span><span class="c9 c114">,</span><span class="c9">&nbsp;</span><span class="c9 c110">empty</span><span class="c9 c114">, or </span><span class="c104 c9 c54">locked</span></p><p class="c6"><span class="c9">&nbsp; if (child is </span><span class="c9 c54">locked</span><span class="c2">) {</span></p><p class="c6"><span class="c9">&nbsp; &nbsp; </span><span class="c37 c9">// can&rsquo;t do anything</span></p><p class="c6"><span class="c9">&nbsp; } else if (child is </span><span class="c9 c110">empty</span><span class="c2">) {</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; attempt to replace empty value with star value (atomic CAS)</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; if (atomic CAS successful) {</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; &nbsp; Move on to next star</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; }</span></p><p class="c6"><span class="c9">&nbsp; } else { </span><span class="c9 c114">// child is a</span><span class="c9">&nbsp;</span><span class="c9 c56 c104">star</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; attempt to lock (atomic CAS)</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; if (lock acquired) {</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; &nbsp; s2 = child value</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; &nbsp; do {</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;allocate&quot; space for a new quad using atomicSub</span></p><p class="c6"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c37 c9">// for new quad</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; determine which quadrant s1 and s2 should be added to</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (stars occupy separate quadrants) {</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; add stars to their respective quadrant</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {</span></p><p class="c6"><span class="c9">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; move on </span><span class="c9 c83">// need to try again for newly allocated quad</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; &nbsp; } while (s1 and s2 in same quad)</span></p><p class="c6"><span class="c2">&nbsp; &nbsp; }</span></p><p class="c6"><span class="c2">&nbsp; }</span></p><p class="c6"><span class="c9">&nbsp; __threadfence() </span><span class="c83 c9">// ensures update has completed before releasing lock</span></p><p class="c6"><span class="c2">&nbsp; if (lock held) {</span></p><p class="c6"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;release lock</span></p><p class="c6"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;put correct quad value back</span></p><p class="c6"><span class="c9">&nbsp; &nbsp; &nbsp; </span><span class="c37 c9">// -2 is the lock value (not a valid quad index)</span></p><p class="c6"><span class="c2">&nbsp; }</span></p><p class="c6"><span class="c9">}</span></p><h2 class="c38" id="h.cvzddd3oxwek"><span class="c61">The Force Calculations Kernel</span></h2><p class="c1"><span class="c3">The design of the force calculations kernel was refined over many iterations. Along the way, we used the C++ chrono library to determine wall clock runtime and used the NVIDIA Nsight profiler to determine what we needed to optimize next.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">Since recursion is not well-suited for GPU execution, our implementation uses a stack to traverse the quadtree. The stack is an array of integers, and it tracks which child value to look at next. We defined the maximum depth of the stack to be 32. This allowed us to statically allocate the stack, but also required us to limit the maximum depth when building the quadtree. A maximum depth of 32 still allows for a large quadtree with many levels.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">The overall idea for each implementation is to statically assign stars to threads, and each thread computes the net force on each of its stars. The problem with statically assigning stars is that it results in bad load balancing. This is because the amount of work needed to calculate the net force on a star varies significantly depending on the star&rsquo;s location, and not only is the amount of work not known at assignment time, it changes every timestep.</span></p><h3 class="c23" id="h.tsejcciuxq91"><span>Force Calculation Attempt #1</span></h3><p class="c1"><span class="c3">In the first implementation of the kernel, each thread had a stack all to itself, and each level of the stack had four spots to put child values. A -1 would represent an empty position in the stack. We launched this kernel with many blocks and 1024 threads per block. The pseudocode for this implementation follows.</span></p><p class="c16 c7"><span class="c2"></span></p><p class="c16"><span class="c2">// note that push and pop take a level argument</span></p><p class="c16"><span class="c2">depth = 0</span></p><p class="c16"><span class="c2">push(root, depth)</span></p><p class="c16"><span class="c2">while (stack is not empty) {</span></p><p class="c16"><span class="c2">&nbsp; child_val = pop(depth)</span></p><p class="c16"><span class="c2">&nbsp; if (child_val == -1) {</span></p><p class="c16"><span class="c2">&nbsp; &nbsp; // nothing to do</span></p><p class="c16"><span class="c2">&nbsp; } else if (child is a star) {</span></p><p class="c16"><span class="c2">&nbsp; &nbsp; // interact with this star</span></p><p class="c16"><span class="c2">&nbsp; &nbsp; Calculate force from other star</span></p><p class="c16"><span class="c2">&nbsp; } else if (child is a quad) {</span></p><p class="c16"><span class="c2">&nbsp; &nbsp; if (far enough away) {</span></p><p class="c16"><span class="c2">&nbsp; &nbsp; &nbsp; Calculate force from quad</span></p><p class="c16"><span class="c2">&nbsp; &nbsp; } else {</span></p><p class="c16"><span class="c2">&nbsp; &nbsp; &nbsp; depth++</span></p><p class="c16"><span class="c2">&nbsp; &nbsp; &nbsp; push all the quad&rsquo;s children onto stack // level has been incremented</span></p><p class="c16"><span class="c2">&nbsp; &nbsp; }</span></p><p class="c16"><span class="c2">&nbsp; }</span></p><p class="c16"><span class="c2">&nbsp; if (level is empty) {</span></p><p class="c16"><span class="c2">&nbsp; &nbsp; depth--</span></p><p class="c16"><span class="c2">&nbsp; }</span></p><p class="c16"><span class="c2">}</span></p><p class="c16 c7"><span class="c2"></span></p><p class="c1"><span class="c3">There are multiple performance problems with this initial implementation. Below is the part of the Nsight profile output for the force kernel.</span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 606.50px; height: 79.11px;"><img alt="" src="images/image11.png" style="width: 606.50px; height: 79.11px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">As you can see, we had a very significant DRAM bottleneck. This is because force calculation has a low arithmetic intensity and there is no memory reuse in this implementation.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">This implementation also suffers from thread divergence as thread work depends significantly on the locations of the stars.</span></p><h3 class="c23" id="h.n1n8zekxt5ju"><span class="c22">Force Calculation Attempt #2</span></h3><p class="c16"><span class="c3">The first improvement to the original kernel involved sharing the stack. We realized that since every thread in a warp executes instructions in lockstep, it makes sense for each thread in a warp to share the same stack. This means that each thread in the warp traverses the same part of the tree at the same time, so memory accesses are coalesced. This helps reduce memory bandwidth use because each thread can make use of the same memory.</span></p><p class="c16 c7"><span class="c3"></span></p><p class="c16"><span class="c3">To get this new design to work, we reduced the block size to 32 (the number of threads in a warp) and allocated a shared stack for each block (warp). Additionally, the stack was modified to only push one child value at a time, instead of all four,.</span></p><p class="c16 c7"><span class="c3"></span></p><p class="c16"><span class="c3">Each block has a &ldquo;stack manager&rdquo; (thread 0 in the block) that manipulates the stack for the rest of the threads. At the beginning, the stack manager also precomputes and saves values that depend only on depth in another shared array to avoid computation later.</span></p><p class="c16 c7"><span class="c3"></span></p><p class="c16"><span>Since each thread in the warp shares the stack, we needed a way to determine if the warp should compute forces on its stars from a quad or continue traversing the quad&rsquo;s children. The CUDA warp-level function </span><span class="c9">__anysync</span><span class="c3">&nbsp;solved this problem by allowing any thread that needed to continue to force the other threads in the warp to continue.</span></p><p class="c16 c7"><span class="c3"></span></p><p class="c1"><span>An interesting outcome is that using </span><span class="c9">__anysync</span><span>&nbsp;results in the algorithm being slightly more accurate. Suppose one thread (we shall refer to as Thread 1) determines that a quad was far enough away from its own star, but another thread (referred to as Thread 2) determines that this same quad is not far enough away. Therefore, Thread 2 must continue traversing the tree at this particular point, while Thread 1 does not. However, it does not benefit Thread 1 to stop traversing the tree and instead use this quad&rsquo;s aggregate values to calculate the force on its star because Thread 1 still has to wait on all the other threads that continue to traverse the tree. Furthermore, this would lead to a worse approximation of the star system because continuing down the quadtree is more accurate, and all threads in the warp must continue anyway.</span><span class="c3">&nbsp;For this kernel design, this leads to a better approximation at no additional cost.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">The resulting Nsight profile shows that the compute throughput increased and memory throughput decreased, as intended.</span></p><p class="c16 c7"><span class="c3"></span></p><p class="c16"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.50px; height: 101.18px;"><img alt="" src="images/image8.png" style="width: 600.50px; height: 101.18px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h3 class="c41" id="h.kbo83hvet62o"><span>Force Calculation Attempt #3</span></h3><p class="c1"><span class="c3">The next optimization for force calculation involved introducing another kernel - a sorting kernel. Sorting occurred before the force calculation kernel, and the output of the sort is an inorder traversal of the quadtree. We implemented this kernel serially, so the kernel itself is not very interesting. However, the sorting is crucial for the force calculation kernel. The inorder traversal results in stars that are nearby in space being nearby in the resulting array.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">Since threads in the warp now calculate forces for stars that are closer together, there is significantly less thread divergence because each thread needs to traverse similar parts of the quadtree, and this results in a substantial speedup. Final speedup values and analysis are available in the results section.</span></p><h3 class="c23" id="h.ojrbk1kcdg52"><span class="c22">Force Kernel Launch Configuration</span></h3><p class="c16"><span>Our final design limited us to using a block size of 32 for our kernel launch. We determined the number of blocks to launch empirically by sweeping over this value and comparing kernel runtimes. The final launch configuration was 46 </span><img src="images/image1.png"><span class="c3">&nbsp;8 = 368 blocks. The value 46 is significant because it is the number of streaming multiprocessors on a GeForce RTX 2080.</span></p><p class="c16 c7"><span class="c3"></span></p><p class="c102"><span class="c3">Unfortunately, our final design had poor occupancy. Occupancy is the ratio of the number of active warps per multiprocessor to the maximum number of possible active warps.</span></p><p class="c88"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 569.50px; height: 73.36px;"><img alt="" src="images/image7.png" style="width: 569.50px; height: 73.36px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c16"><span class="c3">Increasing the block size would result in better occupancy because there would be more warps per block, and the theoretical occupancy is limited by the number of blocks. In our current implementation, this is not possible because the stack is only designed for a single warp.</span></p><p class="c16 c7"><span class="c3"></span></p><p class="c16"><span class="c3">Given more time, we would have improved our stack to work with more warps, enabling us to increase the block size. In this scenario, the shared stack would be &ldquo;wider,&rdquo; but each warp&rsquo;s respective stack manager would only manipulate the part of the stack corresponding to its warp.</span></p><h1 class="c66" id="h.unx0satt4d2r"><span class="c71">Results</span></h1><p class="c1"><span class="c3">In addition to results and approaches listed above, we also took performance measurements of our final implementation, and how they are affected by problem size. Specifically, we investigated this implementation&rsquo;s sensitivity to star count and the theta parameter.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span>We were most concerned with optimizing the force calculation step as this took the longest time to compute serially. We were less concerned with the overall speedup of the entire algorithm because not all of our kernels were optimized. In fact, the sorting kernel is executed serially. This would tend to reduce our overall performance and also cause us to underestimate the percentage of time spent on the force calculation kernel (compared to a parallel sort). Still, we achieve a significant speedup over our sequential implementation. If we had more time, we would implement a parallel sorting kernel.</span></p><h2 class="c38" id="h.nb8jxlw1x2tx"><span class="c61">Force Calculation Sensitivity to Star Count</span></h2><p class="c1"><span class="c3">We measured the impact that the number of stars has on force calculation time as well as total runtime for both our CUDA implementation and our serial implementation. To maintain consistency, all tests (both ones run on the CPU and GPU) were given the same seed for randomness. This ensures consistency in the initial star positions across tests. Additionally, all tests were run with a timestep size of 0.0001 years, computing 60 time steps, with a theta value of 0.2. Below are the results from experiments using 100-1,000,000 stars.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1 c7"><span class="c3"></span></p><table class="c50"><tr class="c10"><td class="c58" colspan="4" rowspan="1"><p class="c29"><span class="c19 c52">Serial Runtime vs Star Count</span></p></td></tr><tr class="c10"><td class="c81" colspan="1" rowspan="1"><p class="c12"><span class="c19">Stars</span></p></td><td class="c42" colspan="1" rowspan="1"><p class="c12"><span class="c19">Force Calculation Time (s)</span></p></td><td class="c75" colspan="1" rowspan="1"><p class="c12 c68"><span class="c19">Total Runtime (s)</span></p></td><td class="c85" colspan="1" rowspan="1"><p class="c12"><span class="c19">Force Calculation Percent of Total Time</span></p></td></tr><tr class="c10"><td class="c20" colspan="1" rowspan="1"><p class="c14"><span class="c0">100</span></p></td><td class="c86" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.0070</span></p></td><td class="c101" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.0081</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c14"><span class="c0">85.9117%</span></p></td></tr><tr class="c10"><td class="c73" colspan="1" rowspan="1"><p class="c14"><span class="c0">1,000</span></p></td><td class="c51" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.3541</span></p></td><td class="c59" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.3650</span></p></td><td class="c84" colspan="1" rowspan="1"><p class="c14"><span class="c0">97.0243%</span></p></td></tr><tr class="c10"><td class="c80" colspan="1" rowspan="1"><p class="c14"><span class="c0">10,000</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c14"><span class="c0">7.9880</span></p></td><td class="c48" colspan="1" rowspan="1"><p class="c14"><span class="c0">8.0994</span></p></td><td class="c105" colspan="1" rowspan="1"><p class="c14"><span class="c0">98.6239%</span></p></td></tr><tr class="c10"><td class="c73" colspan="1" rowspan="1"><p class="c14"><span class="c0">100,000</span></p></td><td class="c51" colspan="1" rowspan="1"><p class="c14"><span class="c0">141.8995</span></p></td><td class="c59" colspan="1" rowspan="1"><p class="c14"><span class="c0">143.6660</span></p></td><td class="c84" colspan="1" rowspan="1"><p class="c14"><span class="c0">98.7704%</span></p></td></tr><tr class="c10"><td class="c35" colspan="1" rowspan="1"><p class="c14"><span class="c0">1,000,000</span></p></td><td class="c99" colspan="1" rowspan="1"><p class="c14"><span class="c0">3090.7263</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c14"><span class="c0">3121.5092</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c14"><span class="c0">99.0138%</span></p></td></tr></table><p class="c1 c7"><span class="c3"></span></p><table class="c50"><tr class="c10"><td class="c58" colspan="4" rowspan="1"><p class="c29"><span class="c19 c52">CUDA Runtime vs Star Count</span></p></td></tr><tr class="c10"><td class="c81" colspan="1" rowspan="1"><p class="c12"><span class="c19">Stars</span></p></td><td class="c42" colspan="1" rowspan="1"><p class="c12"><span class="c19">Force Calculation Time (s)</span></p></td><td class="c75" colspan="1" rowspan="1"><p class="c12 c68"><span class="c19">Total Runtime (s)</span></p></td><td class="c85" colspan="1" rowspan="1"><p class="c12"><span class="c19">Force Calculation Percent of Total Time</span></p></td></tr><tr class="c10"><td class="c20" colspan="1" rowspan="1"><p class="c14"><span class="c0">100</span></p></td><td class="c86" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.0044</span></p></td><td class="c101" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.1081</span></p></td><td class="c5" colspan="1" rowspan="1"><p class="c14"><span class="c0">4.0835%</span></p></td></tr><tr class="c10"><td class="c73" colspan="1" rowspan="1"><p class="c14"><span class="c0">1,000</span></p></td><td class="c51" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.0219</span></p></td><td class="c59" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.1484</span></p></td><td class="c84" colspan="1" rowspan="1"><p class="c14"><span class="c0">14.7334%</span></p></td></tr><tr class="c10"><td class="c80" colspan="1" rowspan="1"><p class="c14"><span class="c0">10,000</span></p></td><td class="c63" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.3179</span></p></td><td class="c48" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.6404</span></p></td><td class="c105" colspan="1" rowspan="1"><p class="c14"><span class="c0">49.6382%</span></p></td></tr><tr class="c10"><td class="c73" colspan="1" rowspan="1"><p class="c14"><span class="c0">100,000</span></p></td><td class="c51" colspan="1" rowspan="1"><p class="c14"><span class="c0">4.5898</span></p></td><td class="c59" colspan="1" rowspan="1"><p class="c14"><span class="c0">7.0570</span></p></td><td class="c84" colspan="1" rowspan="1"><p class="c14"><span class="c0">65.0385%</span></p></td></tr><tr class="c10"><td class="c35" colspan="1" rowspan="1"><p class="c14"><span class="c0">1,000,000</span></p></td><td class="c99" colspan="1" rowspan="1"><p class="c14"><span class="c0">68.7030</span></p></td><td class="c17" colspan="1" rowspan="1"><p class="c14"><span class="c0">96.2523</span></p></td><td class="c28" colspan="1" rowspan="1"><p class="c14"><span class="c0">71.3780%</span></p></td></tr></table><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 308.00px;"><img alt="" src="images/image3.png" style="width: 624.00px; height: 308.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 308.00px;"><img alt="" src="images/image2.png" style="width: 624.00px; height: 308.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c1"><span>T</span><span class="c3">he results above demonstrate that, as one would expect, increasing star count increases runtime. Our implementation exhibits good speedup compared to our serial implementation for large amounts of stars. In practice, it doesn&rsquo;t make sense to use small amounts of stars on GPUs since they can launch thousands of threads.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">We found it interesting that on a log scale for both time and star count, the CUDA implementation and serial implementation had very similar slopes&ndash;they were just offset by a consistent factor of 10.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span>We also looked at the impact that star count has on the speedup of our force calculation kernel. We found a clear trend where the speedup increases as the number of stars (aka the problem size) increases. Our implementation was able to reach up to a 44.9x speedup at 1,000,000 stars. A</span><span>lthough there are some difficulties when running an algorithm that&rsquo;s rather recursive and non-uniform on a GPU, the high quantity of cores and SIMD parallelism </span><span class="c3">makes these tradeoffs worth it, especially for large problem sizes. It is definitely viable to do Barnes-Hut on a GPU, provided the algorithm is optimized enough. Below is a table and a graph of our data.</span></p><p class="c1 c7"><span class="c3"></span></p><table class="c50"><tr class="c10"><td class="c116" colspan="2" rowspan="1"><p class="c100"><span class="c19 c52">Force Calculation Speedup</span></p></td></tr><tr class="c10"><td class="c74" colspan="1" rowspan="1"><p class="c40"><span class="c19">Stars</span></p></td><td class="c95" colspan="1" rowspan="1"><p class="c40"><span class="c19">Speedup</span></p></td></tr><tr class="c10"><td class="c78" colspan="1" rowspan="1"><p class="c21"><span class="c0">100</span></p></td><td class="c98" colspan="1" rowspan="1"><p class="c21"><span class="c0">1.5774</span></p></td></tr><tr class="c10"><td class="c82" colspan="1" rowspan="1"><p class="c21"><span class="c0">1,000</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c21"><span class="c0">16.1950</span></p></td></tr><tr class="c10"><td class="c65" colspan="1" rowspan="1"><p class="c21"><span class="c0">10,000</span></p></td><td class="c32" colspan="1" rowspan="1"><p class="c21"><span class="c0">25.1280</span></p></td></tr><tr class="c10"><td class="c82" colspan="1" rowspan="1"><p class="c21"><span class="c0">100,000</span></p></td><td class="c25" colspan="1" rowspan="1"><p class="c21"><span class="c0">30.9164</span></p></td></tr><tr class="c10"><td class="c103" colspan="1" rowspan="1"><p class="c21"><span class="c0">1,000,000</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c21"><span class="c0">44.9868</span></p></td></tr></table><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 386.67px;"><img alt="" src="images/image16.png" style="width: 624.00px; height: 386.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><h2 class="c38" id="h.gjo1w33091p0"><span>Limits to Speedup</span></h2><p class="c1"><span>The main limitations to speedup are thread divergence, memory bandwidth, and inefficient use of the GPU streaming multiprocessors</span><span>. </span><span class="c3">Not every thread in a warp is always doing &ldquo;useful&rdquo; work. For example, all threads in a warp traverse all parts of the tree that only a subset of threads actually need to traverse. In this situation, the other threads in that warp could have just used aggregate calculations if they didn&rsquo;t have to continue executing in lockstep. Since our implementation does not explicitly disable these threads, the Nsight profiler will report them as doing work, but in actuality they could have been doing something more useful for the progress of the simulation (such as calculating forces on another star).</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">As discussed in earlier sections, force calculation has low arithmetic intensity. We increased memory reuse in the force calculation kernel, and this helped speedup, but it is still a limiting factor. The following Nsight output shows our final values for throughput.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 97.33px;"><img alt="" src="images/image10.png" style="width: 624.00px; height: 97.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">Finally, our implementation is limited by poor SM occupancy. As discussed in earlier sections, occupancy relates to the number of active warps. Our stack implementation limited our block size to 32 (the size of one warp), and this reduced our maximum possible occupancy. The Nsight output is repeated again here for convenience.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c16"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 622.51px; height: 77.96px;"><img alt="" src="images/image7.png" style="width: 622.51px; height: 77.96px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c38" id="h.cxwgqqcrdrd1"><span>Force Calculation Sensitivity to Theta Parameter</span></h2><p class="c1"><span>When computing the net force on a star exerted by the other stars in this system, the N-body O(n</span><span class="c76">2</span><span class="c3">) problem becomes an O(nlogn) problem due to the fact that a star cluster that is sufficiently far away from another star can be approximated as a single body exerting a force on that star.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span>The theta parameter is what is used to decide whether or not a quad is sufficiently far away from a given star and is sufficiently small enough. Given a star and a quad, if the side length of the quad divided by the distance between the star and the center of the quad is less than theta, then that star will treat that quad as an aggregate body exerting some force on it. Should the quotient </span><span class="c52">not</span><span class="c3">&nbsp;be less than theta, then the same process is repeated with quad&rsquo;s sub-quads, until the quotient is less than theta or the quad&rsquo;s child is a star.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">Similar to the previous experiment, all tests were given the same seed for randomness, a timestep size of 0.0001 years, computing 60 time steps, with a star count of 1,000 stars. Below are the results for values of theta ranging from 0.10 to 0.40.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1 c7"><span class="c3"></span></p><table class="c50"><tr class="c33"><td class="c24" colspan="4" rowspan="1"><p class="c29"><span class="c19 c52">Serial Runtime (in seconds) vs Theta Value</span></p></td></tr><tr class="c33"><td class="c57" colspan="1" rowspan="1"><p class="c12"><span class="c19">Theta</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c12"><span class="c19">Force Calc</span></p></td><td class="c109" colspan="1" rowspan="1"><p class="c12"><span class="c19">Total</span></p></td><td class="c94" colspan="1" rowspan="1"><p class="c12"><span class="c19">Percentage</span></p></td></tr><tr class="c33"><td class="c62" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.10</span></p></td><td class="c113" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.5743</span></p></td><td class="c97" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.5836</span></p></td><td class="c90" colspan="1" rowspan="1"><p class="c14"><span class="c0">98.3970%</span></p></td></tr><tr class="c33"><td class="c18" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.15</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.4154</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.4247</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c14"><span class="c0">97.8124%</span></p></td></tr><tr class="c33"><td class="c34" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.20</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.3216</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.3319</span></p></td><td class="c87" colspan="1" rowspan="1"><p class="c14"><span class="c0">96.8777%</span></p></td></tr><tr class="c33"><td class="c18" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.25</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.2483</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.2579</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c14"><span class="c0">96.2422%</span></p></td></tr><tr class="c33"><td class="c34" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.30</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.2059</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.2156</span></p></td><td class="c87" colspan="1" rowspan="1"><p class="c14"><span class="c0">95.5192%</span></p></td></tr><tr class="c33"><td class="c18" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.35</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.1710</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.1806</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c14"><span class="c0">94.7004%</span></p></td></tr><tr class="c33"><td class="c69" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.40</span></p></td><td class="c115" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.1504</span></p></td><td class="c91" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.1599</span></p></td><td class="c53" colspan="1" rowspan="1"><p class="c14"><span class="c0">94.0419%</span></p></td></tr></table><p class="c1 c7"><span class="c3"></span></p><table class="c50"><tr class="c10"><td class="c24" colspan="4" rowspan="1"><p class="c29"><span class="c19 c52">CUDA Runtime (in seconds) vs Theta Value</span></p></td></tr><tr class="c33"><td class="c57" colspan="1" rowspan="1"><p class="c12"><span class="c19">Theta</span></p></td><td class="c55" colspan="1" rowspan="1"><p class="c12"><span class="c19">Force Calc</span></p></td><td class="c109" colspan="1" rowspan="1"><p class="c12"><span class="c19">Total</span></p></td><td class="c94" colspan="1" rowspan="1"><p class="c12"><span class="c19">Percentage</span></p></td></tr><tr class="c33"><td class="c62" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.10</span></p></td><td class="c113" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.0262</span></p></td><td class="c97" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.1418</span></p></td><td class="c90" colspan="1" rowspan="1"><p class="c14"><span class="c0">18.4882%</span></p></td></tr><tr class="c33"><td class="c18" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.15</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.0226</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.1105</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c14"><span class="c0">20.4782%</span></p></td></tr><tr class="c33"><td class="c34" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.20</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.0201</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.1219</span></p></td><td class="c87" colspan="1" rowspan="1"><p class="c14"><span class="c0">16.4496%</span></p></td></tr><tr class="c33"><td class="c18" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.25</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.0176</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.1014</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c14"><span class="c0">17.3407%</span></p></td></tr><tr class="c33"><td class="c34" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.30</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.0153</span></p></td><td class="c70" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.0993</span></p></td><td class="c87" colspan="1" rowspan="1"><p class="c14"><span class="c0">15.4262%</span></p></td></tr><tr class="c33"><td class="c18" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.35</span></p></td><td class="c46" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.01388</span></p></td><td class="c27" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.12502</span></p></td><td class="c43" colspan="1" rowspan="1"><p class="c14"><span class="c0">11.1018%</span></p></td></tr><tr class="c33"><td class="c69" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.40</span></p></td><td class="c115" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.01246</span></p></td><td class="c91" colspan="1" rowspan="1"><p class="c14"><span class="c0">0.11302</span></p></td><td class="c53" colspan="1" rowspan="1"><p class="c14"><span class="c0">11.0289%</span></p></td></tr></table><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 308.00px;"><img alt="" src="images/image12.png" style="width: 624.00px; height: 308.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c1"><span>As one would expect, increasing theta (effectively decreasing problem size) decreases overall runtime for both the CUDA and serial implementations. With the serial implementation, there is a strong, exponential downward trend on the time vs theta value graph. The speedup also gets worse because at smaller problem sizes, the CUDA implementation has more overhead to deal with, relative to the actual force calculations that are happening. Not only that, since there are more threads deciding that they don&rsquo;t need to further traverse the tree, the amount of necessary work being done is also decreasing. Overall, fewer threads are deeming it necessary to traverse the tree further. Below is the speedup data we collected, depicting a downwards trend as theta increases.</span></p><table class="c50"><tr class="c10"><td class="c112" colspan="2" rowspan="1"><p class="c100"><span class="c19 c52">Force Calculation Speedup</span></p></td></tr><tr class="c10"><td class="c49" colspan="1" rowspan="1"><p class="c40"><span class="c19">Theta</span></p></td><td class="c60" colspan="1" rowspan="1"><p class="c40"><span class="c19">Speedup</span></p></td></tr><tr class="c10"><td class="c78" colspan="1" rowspan="1"><p class="c21"><span class="c0">0.10</span></p></td><td class="c98" colspan="1" rowspan="1"><p class="c21"><span class="c0">21.89972455</span></p></td></tr><tr class="c10"><td class="c93" colspan="1" rowspan="1"><p class="c21"><span class="c0">0.15</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c21"><span class="c0">18.34834341</span></p></td></tr><tr class="c10"><td class="c65" colspan="1" rowspan="1"><p class="c21"><span class="c0">0.20</span></p></td><td class="c32" colspan="1" rowspan="1"><p class="c21"><span class="c0">16.03389539</span></p></td></tr><tr class="c10"><td class="c93" colspan="1" rowspan="1"><p class="c21"><span class="c0">0.25</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c21"><span class="c0">14.11259068</span></p></td></tr><tr class="c10"><td class="c65" colspan="1" rowspan="1"><p class="c21"><span class="c0">0.30</span></p></td><td class="c32" colspan="1" rowspan="1"><p class="c21"><span class="c0">13.44601996</span></p></td></tr><tr class="c10"><td class="c93" colspan="1" rowspan="1"><p class="c21"><span class="c0">0.35</span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c21"><span class="c0">12.3206768</span></p></td></tr><tr class="c10"><td class="c103" colspan="1" rowspan="1"><p class="c21"><span class="c0">0.40</span></p></td><td class="c67" colspan="1" rowspan="1"><p class="c21"><span class="c0">12.06294906</span></p></td></tr></table><h2 class="c38 c33" id="h.fjq8uqvhomi6"><span class="c61"></span></h2><p class="c1 c7"><span class="c3"></span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 385.33px;"><img alt="" src="images/image4.png" style="width: 624.00px; height: 385.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c1"><span class="c3">Overall, we were pleased with our final implementation and performance results. We showed that an optimized GPU kernel for force calculation is a viable method to implement Barnes-Hut in parallel, with speedup increasing drastically as problem size increases.</span></p><h1 class="c66" id="h.esnx6ifvumg"><span class="c71">Next Steps</span></h1><p class="c1"><span class="c3">In our undertaking of this project, we set out to build and optimize a Barnes-Hut implementation in CUDA. Based on our findings while writing and testing this code, we are still left with ideas on how to further improve our implementation, along with some more questions about the effects certain changes could have on our performance.</span></p><p class="c1 c7"><span class="c3"></span></p><p class="c1"><span class="c3">If we had more time, we would like to:</span></p><ul class="c30 lst-kix_64t38yuzg7ae-0 start"><li class="c1 c36 li-bullet-0"><span class="c3">Develop a parallel implementation of the sorting kernel</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-1 start"><li class="c1 c11 li-bullet-0"><span class="c3">Since the force kernel has been optimized, this kernel now takes a significant portion of the total runtime</span></li><li class="c1 c11 li-bullet-0"><span class="c3">Then we could examine tradeoffs between the time it takes to sort and the benefit to the force calculations</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-0"><li class="c1 c36 li-bullet-0"><span class="c3">Improve the force calculation stack to work with a larger block size</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-1 start"><li class="c1 c11 li-bullet-0"><span class="c3">This would improve SM occupancy</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-0"><li class="c1 c36 li-bullet-0"><span class="c3">Explore dynamic scheduling for the force calculation kernel</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-1 start"><li class="c1 c11 li-bullet-0"><span class="c3">This would significantly help workload imbalance</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-0"><li class="c1 c36 li-bullet-0"><span class="c3">Explore different sorts for the sorting kernel</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-1 start"><li class="c1 c11 li-bullet-0"><span class="c3">We currently use inorder, but perhaps there are other sorts that would be better</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-0"><li class="c1 c36 li-bullet-0"><span class="c3">Explore our code&rsquo;s performance on non-GHC GPUs</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-1 start"><li class="c1 c11 li-bullet-0"><span class="c3">We could attempt larger problem sizes on GPUs with more memory or see how our code performs on less-powerful GPUs</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-0"><li class="c1 c36 li-bullet-0"><span class="c3">Explore sorting the mass and position arrays</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-1 start"><li class="c1 c11 li-bullet-0"><span class="c3">Could spending more time in the sort kernel lead be a tradeoff for spending less time in the force calculation kernel?</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-0"><li class="c1 c36 li-bullet-0"><span class="c3">Investigate how the uniformity of distribution of stars impacts performance</span></li></ul><ul class="c30 lst-kix_64t38yuzg7ae-1 start"><li class="c1 c11 li-bullet-0"><span class="c3">Configurations where there are lots of tight clumps of stars spread out over large distances would result in a quadtree with many layers and a lot of empty nodes. This is not ideal, so how detrimental is this to performance?</span></li><li class="c1 c11 li-bullet-0"><span>Similarly, configurations where stars are evenly spaced out results in a more compact tree.</span><hr style="page-break-before:always;display:none;"></li></ul><h1 class="c66" id="h.nkk2fomrqm6k"><span class="c71">References</span></h1><p class="c16"><span>Jianqiao Liu, Michael Robson, Thomas Quinn, and Milind Kulkarni. 2019. Efficient GPU tree walks for effective distributed n-body simulations. In Proceedings of the ACM International Conference on Supercomputing (ICS &#39;19). Association for Computing Machinery, New York, NY, USA, 24&ndash;34. </span><span class="c45"><a class="c72" href="https://www.google.com/url?q=https://doi.org/10.1145/3330345.3330348&amp;sa=D&amp;source=editors&amp;ust=1745921182472178&amp;usg=AOvVaw0WlXftWuy0HBYMewTO5J2Y">https://doi.org/10.1145/3330345.3330348</a></span></p><p class="c16 c7"><span class="c3"></span></p><p class="c16"><span class="c3">M. Burtscher and K. Pingali. &quot;An Efficient CUDA Implementation of the Tree-based Barnes Hut n-Body Algorithm&quot;. Chapter 6 in GPU Computing Gems Emerald Edition, pp. 75-92. January 2011.</span></p><p class="c16 c7"><span class="c3"></span></p><p class="c16"><span class="c45"><a class="c72" href="https://www.google.com/url?q=https://userweb.cs.txstate.edu/~mb92/research/ECL-BH/&amp;sa=D&amp;source=editors&amp;ust=1745921182472680&amp;usg=AOvVaw1s4fcvWrhwcQfbhxSISZhf">https://userweb.cs.txstate.edu/~mb92/research/ECL-BH/</a></span><span>&nbsp;- Barnes-Hut CUDA code</span></p><p class="c16 c7"><span class="c3"></span></p><p class="c16"><span class="c45"><a class="c72" href="https://www.google.com/url?q=https://arborjs.org/docs/barnes-hut&amp;sa=D&amp;source=editors&amp;ust=1745921182472893&amp;usg=AOvVaw2Q755UpCemcq4JCQEQ2208">https://arborjs.org/docs/barnes-hut</a></span><span>&nbsp;- diagrams and understanding of the Barnes-Hut algorithm</span></p><p class="c16 c7"><span class="c3"></span></p><p class="c16"><span class="c45"><a class="c72" href="https://www.google.com/url?q=https://beltoforion.de/en/barnes-hut-galaxy-simulator/&amp;sa=D&amp;source=editors&amp;ust=1745921182473152&amp;usg=AOvVaw2SX6itDUHiQYMJFpPx4JCd">https://beltoforion.de/en/barnes-hut-galaxy-simulator/</a></span><span>&nbsp;- more Barnes-Hut descriptions and pseudocode</span></p><h1 class="c66" id="h.9jpafhqarztc"><span class="c71">List of Work by Each Student</span></h1><table class="c50"><tr class="c47"><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c77">Work</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c77">Student</span></p></td></tr><tr class="c47"><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Project Brainstorming and Proposal</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Jacob&ndash;50%, Delaynie&ndash;50%</span></p></td></tr><tr class="c47"><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Barnes-Hut Serial Implementation</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Jacob&ndash;90%, Delaynie&ndash;10%</span></p></td></tr><tr class="c47"><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Tree-Building CUDA Kernel</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Jacob&ndash;60%, Delaynie&ndash;40%</span></p></td></tr><tr class="c47"><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Tree-Aggregation CUDA Kernel</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Jacob&ndash;50%, Delaynie&ndash;50%</span></p></td></tr><tr class="c47"><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Tree-Traversal &amp; Force Calculation</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Jacob&ndash;80%, Delaynie&ndash;20%</span></p></td></tr><tr class="c47"><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Data Collection</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Jacob&ndash;10%, Delaynie&ndash;90%</span></p></td></tr><tr class="c47"><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Data Analysis</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Jacob&ndash;50%, Delaynie&ndash;50%</span></p></td></tr><tr class="c47"><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Final Report and Poster Board</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c3">Jacob&ndash;50%, Delaynie&ndash;50%</span></p></td></tr><tr class="c47"><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c77">Total</span></p></td><td class="c31" colspan="1" rowspan="1"><p class="c8"><span class="c77">Jacob&ndash;55%, Delaynie&ndash;45%</span></p></td></tr></table><p class="c1 c7"><span class="c3"></span></p></body></html>